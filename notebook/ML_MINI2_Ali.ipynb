{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "29841f91-7f00-419c-bd55-ce05d3c57f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bc923f53-8e02-4cc9-ae9d-e2af66ab64b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 160000 entries, 0 to 159999\n",
      "Data columns (total 2 columns):\n",
      " #   Column           Non-Null Count   Dtype \n",
      "---  ------           --------------   ----- \n",
      " 0   sentiment_label  160000 non-null  int64 \n",
      " 1   tweet_text       160000 non-null  object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../data/Sentiment140.tenPercent.sample.tweets.tsv', sep='\\t')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6ceb1874-6ec8-47d7-a97a-55b2d8cb92e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment_label\n",
      "4    80000\n",
      "0    80000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count the frequency of each unique value in the 'sentiment_label' column\n",
    "frequency_count = df['sentiment_label'].value_counts()\n",
    "\n",
    "# Print the result\n",
    "print(frequency_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "70520f66-7e94-49a8-ae80-ae8c29e4dd55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary_sentiment\n",
      "1    80000\n",
      "0    80000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df['binary_sentiment'] = df['sentiment_label'].apply(lambda x: 1 if x == 4 else 0)\n",
    "\n",
    "# Count the frequency of each unique value in the 'sentiment_label' column\n",
    "frequency_count = df['binary_sentiment'].value_counts()\n",
    "\n",
    "# Print the result\n",
    "print(frequency_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ef65e9c7-00be-4e48-8294-3d0b3b823f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.76621875\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.82      0.78     16002\n",
      "           1       0.80      0.72      0.75     15998\n",
      "\n",
      "    accuracy                           0.77     32000\n",
      "   macro avg       0.77      0.77      0.77     32000\n",
      "weighted avg       0.77      0.77      0.77     32000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['tweet_text'], df['binary_sentiment'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert text data into numerical features using CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "X_test_vectorized = vectorizer.transform(X_test)\n",
    "\n",
    "# Train the Naive Bayes classifier\n",
    "nb_classifier = MultinomialNB()\n",
    "nb_classifier.fit(X_train_vectorized, y_train)\n",
    "\n",
    "# Make predictions\n",
    "predictions = nb_classifier.predict(X_test_vectorized)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(classification_report(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "82819adc-c45c-4fd6-a78c-d218489a505c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|███▌                                                                  | 1/20 [00:18<05:57, 18.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20: Training Accuracy: 0.499984375, Precision: 0.5, Recall: 1.5624511734008312e-05, F1: 3.1248046997062684e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|███████                                                               | 2/20 [00:37<05:40, 18.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20: Training Accuracy: 0.515375, Precision: 0.9772286821705426, Recall: 0.031514640167494765, F1: 0.06106015196924288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|██████████▌                                                           | 3/20 [00:56<05:21, 18.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20: Training Accuracy: 0.5994765625, Precision: 0.9595150465468716, Recall: 0.20774350801537453, F1: 0.3415404770161446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██████████████                                                        | 4/20 [01:16<05:05, 19.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20: Training Accuracy: 0.6842421875, Precision: 0.9420474566105634, Recall: 0.3926596043873629, F1: 0.5542848950694207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|█████████████████▌                                                    | 5/20 [01:35<04:45, 19.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20: Training Accuracy: 0.744890625, Precision: 0.9286026797921794, Recall: 0.5305927939751883, F1: 0.6753171856978085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|█████████████████████                                                 | 6/20 [01:53<04:26, 19.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20: Training Accuracy: 0.7864765625, Precision: 0.9159501826183617, Recall: 0.6308552857723196, F1: 0.7471295208312131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|████████████████████████▌                                             | 7/20 [02:13<04:07, 19.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20: Training Accuracy: 0.810375, Precision: 0.9047803406960633, Recall: 0.6937751945251711, F1: 0.7853517041334301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████████████████████████████                                          | 8/20 [02:32<03:50, 19.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20: Training Accuracy: 0.8239453125, Precision: 0.8960932276244149, Recall: 0.7328833473953938, F1: 0.8063121524405441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|███████████████████████████████▌                                      | 9/20 [02:51<03:30, 19.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20: Training Accuracy: 0.830703125, Precision: 0.8884525033034797, Recall: 0.7563826130433424, F1: 0.8171153683855179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|██████████████████████████████████▌                                  | 10/20 [03:10<03:10, 19.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20: Training Accuracy: 0.8360390625, Precision: 0.8827297802295578, Recall: 0.7750539045654823, F1: 0.8253949765801143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████████████████████████████████████▉                               | 11/20 [03:29<02:51, 19.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20: Training Accuracy: 0.8389140625, Precision: 0.8779204488039445, Recall: 0.7873191462766789, F1: 0.8301551083616834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████████████████████▍                           | 12/20 [03:49<02:34, 19.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20: Training Accuracy: 0.84115625, Precision: 0.8741047870335469, Recall: 0.7971313396456361, F1: 0.8338454497907949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|████████████████████████████████████████████▊                        | 13/20 [04:08<02:15, 19.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20: Training Accuracy: 0.8429375, Precision: 0.8710735418427726, Recall: 0.8050373425830443, F1: 0.8367545797063791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|████████████████████████████████████████████████▎                    | 14/20 [04:28<01:55, 19.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20: Training Accuracy: 0.8441328125, Precision: 0.8682639736494507, Recall: 0.8113808943470516, F1: 0.838859228986116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████████████████████████████████████████████████▊                 | 15/20 [04:47<01:36, 19.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20: Training Accuracy: 0.845125, Precision: 0.8655787627023269, Recall: 0.8171619636886347, F1: 0.8406738249855334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████████████████████████████████████████████████████▏             | 16/20 [05:06<01:16, 19.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20: Training Accuracy: 0.846421875, Precision: 0.8641559636041126, Recall: 0.8220836848848474, F1: 0.8425949650887196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|██████████████████████████████████████████████████████████▋          | 17/20 [05:25<00:57, 19.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20: Training Accuracy: 0.847640625, Precision: 0.8630045355173427, Recall: 0.8264897971938376, F1: 0.8443525731068829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|██████████████████████████████████████████████████████████████       | 18/20 [05:44<00:38, 19.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20: Training Accuracy: 0.848890625, Precision: 0.8625353118810274, Recall: 0.8300834348926596, F1: 0.8459982802000064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████████████████████████████████████████████████████████████▌   | 19/20 [06:03<00:19, 19.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20: Training Accuracy: 0.849796875, Precision: 0.8621247412008282, Recall: 0.8327864754226431, F1: 0.8472016912243893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 20/20 [06:23<00:00, 19.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20: Training Accuracy: 0.850890625, Precision: 0.8625415684628548, Recall: 0.8348332864597982, F1: 0.8484612697303648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.75021875\n",
      "Class 0 - Precision: 0.7428588756140457, Recall: 0.765466816647919, F1: 0.7539934135606783, Support: 16002\n",
      "Class 1 - Precision: 0.7580426793888209, Recall: 0.7349668708588574, F1: 0.7463264464121362, Support: 15998\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from tqdm import tqdm  # Import tqdm for the progress bar\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['tweet_text'], df['binary_sentiment'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert text data into numerical features using CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "X_test_vectorized = vectorizer.transform(X_test)\n",
    "\n",
    "# Convert labels to PyTorch tensors\n",
    "y_train = torch.tensor(y_train.values)\n",
    "y_test = torch.tensor(y_test.values)\n",
    "\n",
    "# Define a simple feedforward neural network\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Set hyperparameters\n",
    "input_size = X_train_vectorized.shape[1]\n",
    "hidden_size = 64\n",
    "output_size = 2  # Assuming binary classification (0 and 1)\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "model = SimpleNN(input_size, hidden_size, output_size)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 20\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    # Convert input data to PyTorch tensor\n",
    "    X_train_tensor = torch.tensor(X_train_vectorized.toarray(), dtype=torch.float32)\n",
    "\n",
    "    # Forward pass\n",
    "    outputs = model(X_train_tensor)\n",
    "    loss = criterion(outputs, y_train)\n",
    "\n",
    "    # Backward and optimize\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Evaluate on training set\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_outputs = model(X_train_tensor)\n",
    "        train_predictions = torch.argmax(train_outputs, dim=1).numpy()\n",
    "\n",
    "    # Calculate metrics for training set\n",
    "    train_accuracy = accuracy_score(y_train.numpy(), train_predictions)\n",
    "    train_precision = precision_score(y_train.numpy(), train_predictions)\n",
    "    train_recall = recall_score(y_train.numpy(), train_predictions)\n",
    "    train_f1 = f1_score(y_train.numpy(), train_predictions)\n",
    "\n",
    "    # Print or log the metrics for training set\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs}: Training Accuracy: {train_accuracy}, Precision: {train_precision}, Recall: {train_recall}, F1: {train_f1}')\n",
    "\n",
    "# Evaluate on test set\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    X_test_tensor = torch.tensor(X_test_vectorized.toarray(), dtype=torch.float32)\n",
    "    test_outputs = model(X_test_tensor)\n",
    "    test_predictions = torch.argmax(test_outputs, dim=1).numpy()\n",
    "\n",
    "# Calculate metrics for test set for each class\n",
    "test_accuracy = accuracy_score(y_test.numpy(), test_predictions)\n",
    "test_precision_0 = precision_score(y_test.numpy(), test_predictions, pos_label=0)\n",
    "test_recall_0 = recall_score(y_test.numpy(), test_predictions, pos_label=0)\n",
    "test_f1_0 = f1_score(y_test.numpy(), test_predictions, pos_label=0)\n",
    "test_support_0 = len(y_test[y_test == 0])\n",
    "\n",
    "test_precision_1 = precision_score(y_test.numpy(), test_predictions, pos_label=1)\n",
    "test_recall_1 = recall_score(y_test.numpy(), test_predictions, pos_label=1)\n",
    "test_f1_1 = f1_score(y_test.numpy(), test_predictions, pos_label=1)\n",
    "test_support_1 = len(y_test[y_test == 1])\n",
    "\n",
    "# Print or log the metrics for test set for each class\n",
    "print(f'Test Accuracy: {test_accuracy}')\n",
    "print(f'Class 0 - Precision: {test_precision_0}, Recall: {test_recall_0}, F1: {test_f1_0}, Support: {test_support_0}')\n",
    "print(f'Class 1 - Precision: {test_precision_1}, Recall: {test_recall_1}, F1: {test_f1_1}, Support: {test_support_1}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1071e3-e863-40cf-9803-3d00ee955b84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
