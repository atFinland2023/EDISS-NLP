2024-02-18 08:06:11 - INFO - ==========New Line==========
2024-02-18 08:06:11 - INFO - For 0 sample, the processed tweet content is: hey dear happy friday to you already had your rice is bowl for lunch
2024-02-18 08:06:11 - INFO - For 1 sample, the processed tweet content is: ughhh layin downnnn waiting for zeina to cook breakfast
2024-02-18 08:06:11 - INFO - For 2 sample, the processed tweet content is: i reckon he will play even if he is not but i know nothing it wont be the same without him
2024-02-18 08:06:11 - INFO - For 3 sample, the processed tweet content is: i know saw it on the news
2024-02-18 08:06:11 - INFO - For 4 sample, the processed tweet content is: very sad that has closed down one of the few web services that i have used for over years
2024-02-18 08:06:35 - INFO - Training and evaluating Logistic Regression...
2024-02-18 08:06:35 - INFO - Training and evaluating Multinomial Naive Bayes...
2024-02-18 08:06:35 - INFO - Accuracy for Multinomial Naive Bayes: 0.7707556919607904
2024-02-18 08:06:35 - INFO - Classification Report for Multinomial Naive Bayes:
              precision    recall  f1-score   support

           0       0.75      0.81      0.78     15981
           1       0.79      0.73      0.76     15950

    accuracy                           0.77     31931
   macro avg       0.77      0.77      0.77     31931
weighted avg       0.77      0.77      0.77     31931

2024-02-18 08:06:35 - INFO - --------------------------------------------------
2024-02-18 08:06:39 - INFO - Accuracy for Logistic Regression: 0.7841595941248317
2024-02-18 08:06:39 - INFO - Classification Report for Logistic Regression:
              precision    recall  f1-score   support

           0       0.79      0.77      0.78     15981
           1       0.78      0.80      0.79     15950

    accuracy                           0.78     31931
   macro avg       0.78      0.78      0.78     31931
weighted avg       0.78      0.78      0.78     31931

2024-02-18 08:06:39 - INFO - --------------------------------------------------
2024-02-18 08:06:40 - INFO - Number of Tokenized features are 40
2024-02-18 08:07:55 - INFO - Epoch [1/10], Loss: 0.5726, Accuracy: 68.22%
2024-02-18 08:07:56 - INFO - Epoch [1/10], Validation Loss: 0.4955, Validation Accuracy: 75.58%
2024-02-18 08:08:55 - INFO - Epoch [2/10], Loss: 0.4554, Accuracy: 78.68%
2024-02-18 08:08:56 - INFO - Epoch [2/10], Validation Loss: 0.4555, Validation Accuracy: 78.53%
2024-02-18 08:09:55 - INFO - Epoch [3/10], Loss: 0.4126, Accuracy: 81.28%
2024-02-18 08:09:56 - INFO - Epoch [3/10], Validation Loss: 0.4471, Validation Accuracy: 79.15%
2024-02-18 08:10:55 - INFO - Epoch [4/10], Loss: 0.3760, Accuracy: 83.25%
2024-02-18 08:10:56 - INFO - Epoch [4/10], Validation Loss: 0.4460, Validation Accuracy: 79.32%
2024-02-18 08:11:55 - INFO - Epoch [5/10], Loss: 0.3391, Accuracy: 85.21%
2024-02-18 08:11:56 - INFO - Epoch [5/10], Validation Loss: 0.4607, Validation Accuracy: 79.55%
2024-02-18 08:12:55 - INFO - Epoch [6/10], Loss: 0.3005, Accuracy: 87.15%
2024-02-18 08:12:56 - INFO - Epoch [6/10], Validation Loss: 0.4709, Validation Accuracy: 79.11%
2024-02-18 08:13:54 - INFO - Epoch [7/10], Loss: 0.2584, Accuracy: 89.32%
2024-02-18 08:13:55 - INFO - Epoch [7/10], Validation Loss: 0.5066, Validation Accuracy: 78.63%
2024-02-18 08:14:54 - INFO - Epoch [8/10], Loss: 0.2166, Accuracy: 91.27%
2024-02-18 08:14:55 - INFO - Epoch [8/10], Validation Loss: 0.6083, Validation Accuracy: 78.68%
2024-02-18 08:15:53 - INFO - Epoch [9/10], Loss: 0.1786, Accuracy: 93.04%
2024-02-18 08:15:55 - INFO - Epoch [9/10], Validation Loss: 0.6278, Validation Accuracy: 78.08%
2024-02-18 08:16:53 - INFO - Epoch [10/10], Loss: 0.1452, Accuracy: 94.52%
2024-02-18 08:16:54 - INFO - Epoch [10/10], Validation Loss: 0.6894, Validation Accuracy: 77.59%
2024-02-18 08:16:55 - INFO - Test Loss: 0.7037, Test Accuracy: 77.25%
2024-02-18 08:19:17 - INFO - ==========New Line==========
2024-02-18 08:19:17 - INFO - For 0 sample, the processed tweet content is: hey dear happy friday to you already had your rice is bowl for lunch
2024-02-18 08:19:17 - INFO - For 1 sample, the processed tweet content is: ughhh layin downnnn waiting for zeina to cook breakfast
2024-02-18 08:19:17 - INFO - For 2 sample, the processed tweet content is: i reckon he will play even if he is not but i know nothing it wont be the same without him
2024-02-18 08:19:17 - INFO - For 3 sample, the processed tweet content is: i know saw it on the news
2024-02-18 08:19:17 - INFO - For 4 sample, the processed tweet content is: very sad that has closed down one of the few web services that i have used for over years
2024-02-18 08:19:40 - INFO - Training and evaluating Logistic Regression...
2024-02-18 08:19:40 - INFO - Training and evaluating Multinomial Naive Bayes...
2024-02-18 08:19:40 - INFO - Accuracy for Multinomial Naive Bayes: 0.7671541761924149
2024-02-18 08:19:41 - INFO - Classification Report for Multinomial Naive Bayes:
              precision    recall  f1-score   support

           0       0.75      0.80      0.77     15963
           1       0.78      0.74      0.76     15968

    accuracy                           0.77     31931
   macro avg       0.77      0.77      0.77     31931
weighted avg       0.77      0.77      0.77     31931

2024-02-18 08:19:41 - INFO - --------------------------------------------------
2024-02-18 08:19:44 - INFO - Accuracy for Logistic Regression: 0.7816855093795998
2024-02-18 08:19:44 - INFO - Classification Report for Logistic Regression:
              precision    recall  f1-score   support

           0       0.79      0.77      0.78     15963
           1       0.77      0.80      0.79     15968

    accuracy                           0.78     31931
   macro avg       0.78      0.78      0.78     31931
weighted avg       0.78      0.78      0.78     31931

2024-02-18 08:19:44 - INFO - --------------------------------------------------
2024-02-18 08:19:45 - INFO - Number of Tokenized features are 40
2024-02-18 08:21:59 - INFO - Epoch [1/10], Loss: 0.6006, Accuracy: 65.34%
2024-02-18 08:22:01 - INFO - Epoch [1/10], Validation Loss: 0.5106, Validation Accuracy: 74.71%
2024-02-18 08:23:50 - INFO - Epoch [2/10], Loss: 0.4783, Accuracy: 77.07%
2024-02-18 08:23:52 - INFO - Epoch [2/10], Validation Loss: 0.4743, Validation Accuracy: 77.13%
2024-02-18 08:25:41 - INFO - Epoch [3/10], Loss: 0.4366, Accuracy: 79.80%
2024-02-18 08:25:43 - INFO - Epoch [3/10], Validation Loss: 0.4638, Validation Accuracy: 78.10%
2024-02-18 08:27:30 - INFO - Epoch [4/10], Loss: 0.4053, Accuracy: 81.63%
2024-02-18 08:27:32 - INFO - Epoch [4/10], Validation Loss: 0.4528, Validation Accuracy: 79.19%
2024-02-18 08:29:20 - INFO - Epoch [5/10], Loss: 0.3749, Accuracy: 83.28%
2024-02-18 08:29:22 - INFO - Epoch [5/10], Validation Loss: 0.4491, Validation Accuracy: 79.10%
2024-02-18 08:31:14 - INFO - Epoch [6/10], Loss: 0.3428, Accuracy: 85.06%
2024-02-18 08:31:16 - INFO - Epoch [6/10], Validation Loss: 0.4642, Validation Accuracy: 78.72%
2024-02-18 08:33:04 - INFO - Epoch [7/10], Loss: 0.3077, Accuracy: 86.86%
2024-02-18 08:33:06 - INFO - Epoch [7/10], Validation Loss: 0.4845, Validation Accuracy: 78.45%
2024-02-18 08:34:53 - INFO - Epoch [8/10], Loss: 0.2686, Accuracy: 88.91%
2024-02-18 08:34:55 - INFO - Epoch [8/10], Validation Loss: 0.5380, Validation Accuracy: 78.19%
2024-02-18 08:36:42 - INFO - Epoch [9/10], Loss: 0.2295, Accuracy: 90.68%
2024-02-18 08:36:44 - INFO - Epoch [9/10], Validation Loss: 0.5962, Validation Accuracy: 77.83%
2024-02-18 08:38:31 - INFO - Epoch [10/10], Loss: 0.1892, Accuracy: 92.60%
2024-02-18 08:38:33 - INFO - Epoch [10/10], Validation Loss: 0.6844, Validation Accuracy: 77.31%
2024-02-18 08:38:35 - INFO - Test Loss: 0.6729, Test Accuracy: 77.83%
2024-02-18 08:39:12 - INFO - ==========New Line==========
2024-02-18 08:39:12 - INFO - For 0 sample, the processed tweet content is: hey dear happy friday to you already had your rice is bowl for lunch
2024-02-18 08:39:12 - INFO - For 1 sample, the processed tweet content is: ughhh layin downnnn waiting for zeina to cook breakfast
2024-02-18 08:39:12 - INFO - For 2 sample, the processed tweet content is: i reckon he will play even if he is not but i know nothing it wont be the same without him
2024-02-18 08:39:12 - INFO - For 3 sample, the processed tweet content is: i know saw it on the news
2024-02-18 08:39:12 - INFO - For 4 sample, the processed tweet content is: very sad that has closed down one of the few web services that i have used for over years
2024-02-18 08:39:36 - INFO - Training and evaluating Logistic Regression...
2024-02-18 08:39:36 - INFO - Training and evaluating Multinomial Naive Bayes...
2024-02-18 08:39:36 - INFO - Accuracy for Multinomial Naive Bayes: 0.7671541761924149
2024-02-18 08:39:36 - INFO - Classification Report for Multinomial Naive Bayes:
              precision    recall  f1-score   support

           0       0.75      0.80      0.77     15963
           1       0.78      0.74      0.76     15968

    accuracy                           0.77     31931
   macro avg       0.77      0.77      0.77     31931
weighted avg       0.77      0.77      0.77     31931

2024-02-18 08:39:36 - INFO - --------------------------------------------------
2024-02-18 08:39:40 - INFO - Accuracy for Logistic Regression: 0.7816855093795998
2024-02-18 08:39:40 - INFO - Classification Report for Logistic Regression:
              precision    recall  f1-score   support

           0       0.79      0.77      0.78     15963
           1       0.77      0.80      0.79     15968

    accuracy                           0.78     31931
   macro avg       0.78      0.78      0.78     31931
weighted avg       0.78      0.78      0.78     31931

2024-02-18 08:39:40 - INFO - --------------------------------------------------
2024-02-18 08:39:41 - INFO - Number of Tokenized features are 40
2024-02-18 08:39:56 - INFO - embed_size:300
2024-02-18 08:39:56 - INFO - hidden_size:256
2024-02-18 08:39:56 - INFO - output_size:1
2024-02-18 08:39:56 - INFO - batch_size:8
2024-02-18 08:39:56 - INFO - learning_rate:0.0001
2024-02-18 08:41:54 - INFO - Epoch [1/10], Loss: 0.5537, Accuracy: 70.06%
2024-02-18 08:41:57 - INFO - Epoch [1/10], Validation Loss: 0.4827, Validation Accuracy: 76.66%
2024-02-18 08:43:53 - INFO - Epoch [2/10], Loss: 0.4416, Accuracy: 79.50%
2024-02-18 08:43:55 - INFO - Epoch [2/10], Validation Loss: 0.4588, Validation Accuracy: 78.33%
2024-02-18 08:45:52 - INFO - Epoch [3/10], Loss: 0.3928, Accuracy: 82.22%
2024-02-18 08:45:54 - INFO - Epoch [3/10], Validation Loss: 0.4437, Validation Accuracy: 79.63%
2024-02-18 08:47:52 - INFO - Epoch [4/10], Loss: 0.3461, Accuracy: 84.80%
2024-02-18 08:47:54 - INFO - Epoch [4/10], Validation Loss: 0.4574, Validation Accuracy: 79.32%
2024-02-18 08:49:51 - INFO - Epoch [5/10], Loss: 0.2933, Accuracy: 87.58%
2024-02-18 08:49:53 - INFO - Epoch [5/10], Validation Loss: 0.4792, Validation Accuracy: 79.12%
2024-02-18 08:51:49 - INFO - Epoch [6/10], Loss: 0.2382, Accuracy: 90.26%
2024-02-18 08:51:51 - INFO - Epoch [6/10], Validation Loss: 0.5470, Validation Accuracy: 78.92%
2024-02-18 08:53:47 - INFO - Epoch [7/10], Loss: 0.1839, Accuracy: 92.79%
2024-02-18 08:53:49 - INFO - Epoch [7/10], Validation Loss: 0.6165, Validation Accuracy: 78.16%
2024-02-18 08:55:47 - INFO - Epoch [8/10], Loss: 0.1383, Accuracy: 94.82%
2024-02-18 08:55:49 - INFO - Epoch [8/10], Validation Loss: 0.7038, Validation Accuracy: 77.83%
2024-02-18 08:57:45 - INFO - Epoch [9/10], Loss: 0.1038, Accuracy: 96.28%
2024-02-18 08:57:48 - INFO - Epoch [9/10], Validation Loss: 0.7749, Validation Accuracy: 77.23%
2024-02-18 08:59:43 - INFO - Epoch [10/10], Loss: 0.0812, Accuracy: 97.18%
2024-02-18 08:59:46 - INFO - Epoch [10/10], Validation Loss: 0.8998, Validation Accuracy: 77.06%
2024-02-18 08:59:48 - INFO - Test Loss: 0.8999, Test Accuracy: 77.30%
2024-02-18 09:00:59 - INFO - ==========New Line==========
2024-02-18 09:00:59 - INFO - For 0 sample, the processed tweet content is: hey dear happy friday to you already had your rice is bowl for lunch
2024-02-18 09:00:59 - INFO - For 1 sample, the processed tweet content is: ughhh layin downnnn waiting for zeina to cook breakfast
2024-02-18 09:00:59 - INFO - For 2 sample, the processed tweet content is: i reckon he will play even if he is not but i know nothing it wont be the same without him
2024-02-18 09:00:59 - INFO - For 3 sample, the processed tweet content is: i know saw it on the news
2024-02-18 09:00:59 - INFO - For 4 sample, the processed tweet content is: very sad that has closed down one of the few web services that i have used for over years
2024-02-18 09:01:22 - INFO - Training and evaluating Logistic Regression...
2024-02-18 09:01:22 - INFO - Training and evaluating Multinomial Naive Bayes...
2024-02-18 09:01:22 - INFO - Accuracy for Multinomial Naive Bayes: 0.7671541761924149
2024-02-18 09:01:23 - INFO - Classification Report for Multinomial Naive Bayes:
              precision    recall  f1-score   support

           0       0.75      0.80      0.77     15963
           1       0.78      0.74      0.76     15968

    accuracy                           0.77     31931
   macro avg       0.77      0.77      0.77     31931
weighted avg       0.77      0.77      0.77     31931

2024-02-18 09:01:23 - INFO - --------------------------------------------------
2024-02-18 09:01:26 - INFO - Accuracy for Logistic Regression: 0.7816855093795998
2024-02-18 09:01:27 - INFO - Classification Report for Logistic Regression:
              precision    recall  f1-score   support

           0       0.79      0.77      0.78     15963
           1       0.77      0.80      0.79     15968

    accuracy                           0.78     31931
   macro avg       0.78      0.78      0.78     31931
weighted avg       0.78      0.78      0.78     31931

2024-02-18 09:01:27 - INFO - --------------------------------------------------
2024-02-18 09:01:27 - INFO - Number of Tokenized features are 40
2024-02-18 09:01:42 - INFO - embed_size:300
2024-02-18 09:01:42 - INFO - hidden_size:512
2024-02-18 09:01:42 - INFO - output_size:1
2024-02-18 09:01:42 - INFO - batch_size:8
2024-02-18 09:01:42 - INFO - learning_rate:0.0001
2024-02-18 09:03:42 - INFO - Epoch [1/10], Loss: 0.5586, Accuracy: 69.53%
2024-02-18 09:03:44 - INFO - Epoch [1/10], Validation Loss: 0.4839, Validation Accuracy: 76.84%
2024-02-18 09:05:42 - INFO - Epoch [2/10], Loss: 0.4430, Accuracy: 79.43%
2024-02-18 09:05:45 - INFO - Epoch [2/10], Validation Loss: 0.4486, Validation Accuracy: 79.16%
2024-02-18 09:07:42 - INFO - Epoch [3/10], Loss: 0.3889, Accuracy: 82.45%
2024-02-18 09:07:45 - INFO - Epoch [3/10], Validation Loss: 0.4418, Validation Accuracy: 79.44%
2024-02-18 09:09:42 - INFO - Epoch [4/10], Loss: 0.3306, Accuracy: 85.63%
2024-02-18 09:09:45 - INFO - Epoch [4/10], Validation Loss: 0.4520, Validation Accuracy: 79.32%
2024-02-18 09:11:42 - INFO - Epoch [5/10], Loss: 0.2608, Accuracy: 89.10%
2024-02-18 09:11:44 - INFO - Epoch [5/10], Validation Loss: 0.5060, Validation Accuracy: 79.32%
2024-02-18 09:13:42 - INFO - Epoch [6/10], Loss: 0.1862, Accuracy: 92.63%
2024-02-18 09:13:44 - INFO - Epoch [6/10], Validation Loss: 0.6200, Validation Accuracy: 78.95%
2024-02-18 09:15:41 - INFO - Epoch [7/10], Loss: 0.1252, Accuracy: 95.30%
2024-02-18 09:15:44 - INFO - Epoch [7/10], Validation Loss: 0.7257, Validation Accuracy: 77.88%
2024-02-18 09:17:40 - INFO - Epoch [8/10], Loss: 0.0889, Accuracy: 96.88%
2024-02-18 09:17:43 - INFO - Epoch [8/10], Validation Loss: 0.8121, Validation Accuracy: 78.15%
2024-02-18 09:19:40 - INFO - Epoch [9/10], Loss: 0.0687, Accuracy: 97.67%
2024-02-18 09:19:42 - INFO - Epoch [9/10], Validation Loss: 0.8522, Validation Accuracy: 77.23%
2024-02-18 09:21:39 - INFO - Epoch [10/10], Loss: 0.0546, Accuracy: 98.21%
2024-02-18 09:21:42 - INFO - Epoch [10/10], Validation Loss: 0.9161, Validation Accuracy: 77.55%
2024-02-18 09:21:44 - INFO - Test Loss: 0.9170, Test Accuracy: 77.68%
2024-02-18 09:22:03 - INFO - ==========New Line==========
2024-02-18 09:22:03 - INFO - For 0 sample, the processed tweet content is: hey dear happy friday to you already had your rice is bowl for lunch
2024-02-18 09:22:03 - INFO - For 1 sample, the processed tweet content is: ughhh layin downnnn waiting for zeina to cook breakfast
2024-02-18 09:22:03 - INFO - For 2 sample, the processed tweet content is: i reckon he will play even if he is not but i know nothing it wont be the same without him
2024-02-18 09:22:03 - INFO - For 3 sample, the processed tweet content is: i know saw it on the news
2024-02-18 09:22:03 - INFO - For 4 sample, the processed tweet content is: very sad that has closed down one of the few web services that i have used for over years
2024-02-18 09:22:26 - INFO - Training and evaluating Logistic Regression...
2024-02-18 09:22:27 - INFO - Training and evaluating Multinomial Naive Bayes...
2024-02-18 09:22:27 - INFO - Accuracy for Multinomial Naive Bayes: 0.7671541761924149
2024-02-18 09:22:28 - INFO - Classification Report for Multinomial Naive Bayes:
              precision    recall  f1-score   support

           0       0.75      0.80      0.77     15963
           1       0.78      0.74      0.76     15968

    accuracy                           0.77     31931
   macro avg       0.77      0.77      0.77     31931
weighted avg       0.77      0.77      0.77     31931

2024-02-18 09:22:28 - INFO - --------------------------------------------------
2024-02-18 09:22:31 - INFO - Accuracy for Logistic Regression: 0.7816855093795998
2024-02-18 09:22:31 - INFO - Classification Report for Logistic Regression:
              precision    recall  f1-score   support

           0       0.79      0.77      0.78     15963
           1       0.77      0.80      0.79     15968

    accuracy                           0.78     31931
   macro avg       0.78      0.78      0.78     31931
weighted avg       0.78      0.78      0.78     31931

2024-02-18 09:22:31 - INFO - --------------------------------------------------
2024-02-18 09:22:32 - INFO - Number of Tokenized features are 40
2024-02-18 09:22:47 - INFO - embed_size:512
2024-02-18 09:22:47 - INFO - hidden_size:512
2024-02-18 09:22:47 - INFO - output_size:1
2024-02-18 09:22:47 - INFO - batch_size:4
2024-02-18 09:22:47 - INFO - learning_rate:0.0001
2024-02-18 09:27:06 - INFO - Epoch [1/10], Loss: 0.5412, Accuracy: 71.62%
2024-02-18 09:40:59 - INFO - ==========New Line==========
2024-02-18 09:40:59 - INFO - For 0 sample, the processed tweet content is: hey dear happy friday to you already had your rice is bowl for lunch
2024-02-18 09:40:59 - INFO - For 1 sample, the processed tweet content is: ughhh layin downnnn waiting for zeina to cook breakfast
2024-02-18 09:40:59 - INFO - For 2 sample, the processed tweet content is: i reckon he will play even if he is not but i know nothing it wont be the same without him
2024-02-18 09:40:59 - INFO - For 3 sample, the processed tweet content is: i know saw it on the news
2024-02-18 09:40:59 - INFO - For 4 sample, the processed tweet content is: very sad that has closed down one of the few web services that i have used for over years
2024-02-18 09:41:22 - INFO - Training and evaluating Logistic Regression...
2024-02-18 09:41:23 - INFO - Training and evaluating Multinomial Naive Bayes...
2024-02-18 09:41:23 - INFO - Accuracy for Multinomial Naive Bayes: 0.7671541761924149
2024-02-18 09:41:23 - INFO - Classification Report for Multinomial Naive Bayes:
              precision    recall  f1-score   support

           0       0.75      0.80      0.77     15963
           1       0.78      0.74      0.76     15968

    accuracy                           0.77     31931
   macro avg       0.77      0.77      0.77     31931
weighted avg       0.77      0.77      0.77     31931

2024-02-18 09:41:23 - INFO - --------------------------------------------------
2024-02-18 09:41:27 - INFO - Accuracy for Logistic Regression: 0.7816855093795998
2024-02-18 09:41:27 - INFO - Classification Report for Logistic Regression:
              precision    recall  f1-score   support

           0       0.79      0.77      0.78     15963
           1       0.77      0.80      0.79     15968

    accuracy                           0.78     31931
   macro avg       0.78      0.78      0.78     31931
weighted avg       0.78      0.78      0.78     31931

2024-02-18 09:41:27 - INFO - --------------------------------------------------
2024-02-18 09:41:28 - INFO - Number of Tokenized features are 40
2024-02-18 09:41:43 - INFO - embed_size:300
2024-02-18 09:41:43 - INFO - hidden_size:512
2024-02-18 09:41:43 - INFO - output_size:1
2024-02-18 09:41:43 - INFO - batch_size:4
2024-02-18 09:41:43 - INFO - learning_rate:0.0001
2024-02-18 09:45:33 - INFO - Epoch [1/10], Loss: 0.5633, Accuracy: 68.96%
2024-02-18 09:47:02 - INFO - ==========New Line==========
2024-02-18 09:47:02 - INFO - For 0 sample, the processed tweet content is: hey dear happy friday to you already had your rice is bowl for lunch
2024-02-18 09:47:02 - INFO - For 1 sample, the processed tweet content is: ughhh layin downnnn waiting for zeina to cook breakfast
2024-02-18 09:47:02 - INFO - For 2 sample, the processed tweet content is: i reckon he will play even if he is not but i know nothing it wont be the same without him
2024-02-18 09:47:02 - INFO - For 3 sample, the processed tweet content is: i know saw it on the news
2024-02-18 09:47:02 - INFO - For 4 sample, the processed tweet content is: very sad that has closed down one of the few web services that i have used for over years
2024-02-18 09:47:28 - INFO - Training and evaluating Logistic Regression...
2024-02-18 09:47:28 - INFO - Training and evaluating Multinomial Naive Bayes...
2024-02-18 09:47:28 - INFO - Accuracy for Multinomial Naive Bayes: 0.7671541761924149
2024-02-18 09:47:29 - INFO - Classification Report for Multinomial Naive Bayes:
              precision    recall  f1-score   support

           0       0.75      0.80      0.77     15963
           1       0.78      0.74      0.76     15968

    accuracy                           0.77     31931
   macro avg       0.77      0.77      0.77     31931
weighted avg       0.77      0.77      0.77     31931

2024-02-18 09:47:29 - INFO - --------------------------------------------------
2024-02-18 09:47:32 - INFO - Accuracy for Logistic Regression: 0.7816855093795998
2024-02-18 09:47:33 - INFO - Classification Report for Logistic Regression:
              precision    recall  f1-score   support

           0       0.79      0.77      0.78     15963
           1       0.77      0.80      0.79     15968

    accuracy                           0.78     31931
   macro avg       0.78      0.78      0.78     31931
weighted avg       0.78      0.78      0.78     31931

2024-02-18 09:47:33 - INFO - --------------------------------------------------
2024-02-18 09:47:33 - INFO - Number of Tokenized features are 40
2024-02-18 09:47:48 - INFO - embed_size:256
2024-02-18 09:47:48 - INFO - hidden_size:256
2024-02-18 09:47:48 - INFO - output_size:1
2024-02-18 09:47:48 - INFO - batch_size:4
2024-02-18 09:47:48 - INFO - learning_rate:0.0001
2024-02-18 09:51:23 - INFO - Epoch [1/10], Loss: 0.5479, Accuracy: 70.81%
2024-02-18 09:51:54 - INFO - ==========New Line==========
2024-02-18 09:51:54 - INFO - For 0 sample, the processed tweet content is: hey dear happy friday to you already had your rice is bowl for lunch
2024-02-18 09:51:54 - INFO - For 1 sample, the processed tweet content is: ughhh layin downnnn waiting for zeina to cook breakfast
2024-02-18 09:51:54 - INFO - For 2 sample, the processed tweet content is: i reckon he will play even if he is not but i know nothing it wont be the same without him
2024-02-18 09:51:54 - INFO - For 3 sample, the processed tweet content is: i know saw it on the news
2024-02-18 09:51:54 - INFO - For 4 sample, the processed tweet content is: very sad that has closed down one of the few web services that i have used for over years
2024-02-18 09:52:15 - INFO - ==========New Line==========
2024-02-18 09:52:15 - INFO - For 0 sample, the processed tweet content is: hey dear happy friday to you already had your rice is bowl for lunch
2024-02-18 09:52:15 - INFO - For 1 sample, the processed tweet content is: ughhh layin downnnn waiting for zeina to cook breakfast
2024-02-18 09:52:15 - INFO - For 2 sample, the processed tweet content is: i reckon he will play even if he is not but i know nothing it wont be the same without him
2024-02-18 09:52:15 - INFO - For 3 sample, the processed tweet content is: i know saw it on the news
2024-02-18 09:52:15 - INFO - For 4 sample, the processed tweet content is: very sad that has closed down one of the few web services that i have used for over years
2024-02-18 09:52:38 - INFO - Training and evaluating Logistic Regression...
2024-02-18 09:52:38 - INFO - Training and evaluating Multinomial Naive Bayes...
2024-02-18 09:52:38 - INFO - Accuracy for Multinomial Naive Bayes: 0.7671541761924149
2024-02-18 09:52:39 - INFO - Classification Report for Multinomial Naive Bayes:
              precision    recall  f1-score   support

           0       0.75      0.80      0.77     15963
           1       0.78      0.74      0.76     15968

    accuracy                           0.77     31931
   macro avg       0.77      0.77      0.77     31931
weighted avg       0.77      0.77      0.77     31931

2024-02-18 09:52:39 - INFO - --------------------------------------------------
2024-02-18 09:52:42 - INFO - Accuracy for Logistic Regression: 0.7816855093795998
2024-02-18 09:52:43 - INFO - Classification Report for Logistic Regression:
              precision    recall  f1-score   support

           0       0.79      0.77      0.78     15963
           1       0.77      0.80      0.79     15968

    accuracy                           0.78     31931
   macro avg       0.78      0.78      0.78     31931
weighted avg       0.78      0.78      0.78     31931

2024-02-18 09:52:43 - INFO - --------------------------------------------------
2024-02-18 09:52:44 - INFO - Number of Tokenized features are 40
2024-02-18 09:52:59 - INFO - embed_size:512
2024-02-18 09:52:59 - INFO - hidden_size:512
2024-02-18 09:52:59 - INFO - output_size:1
2024-02-18 09:52:59 - INFO - batch_size:8
2024-02-18 09:52:59 - INFO - learning_rate:0.0001
2024-02-18 09:55:07 - INFO - Epoch [1/10], Loss: 0.5322, Accuracy: 72.16%
2024-02-18 09:55:10 - INFO - Epoch [1/10], Validation Loss: 0.4744, Validation Accuracy: 77.73%
2024-02-18 09:57:16 - INFO - Epoch [2/10], Loss: 0.4208, Accuracy: 80.65%
2024-02-18 09:57:19 - INFO - Epoch [2/10], Validation Loss: 0.4452, Validation Accuracy: 79.24%
2024-02-18 09:59:23 - INFO - Epoch [3/10], Loss: 0.3566, Accuracy: 84.25%
2024-02-18 09:59:26 - INFO - Epoch [3/10], Validation Loss: 0.4382, Validation Accuracy: 79.98%
2024-02-18 10:01:30 - INFO - Epoch [4/10], Loss: 0.2822, Accuracy: 88.15%
2024-02-18 10:01:33 - INFO - Epoch [4/10], Validation Loss: 0.4818, Validation Accuracy: 79.57%
2024-02-18 10:03:37 - INFO - Epoch [5/10], Loss: 0.1964, Accuracy: 92.20%
2024-02-18 10:03:40 - INFO - Epoch [5/10], Validation Loss: 0.5685, Validation Accuracy: 78.95%
2024-02-18 10:05:43 - INFO - Epoch [6/10], Loss: 0.1258, Accuracy: 95.34%
2024-02-18 10:05:46 - INFO - Epoch [6/10], Validation Loss: 0.7067, Validation Accuracy: 78.14%
2024-02-18 10:07:51 - INFO - Epoch [7/10], Loss: 0.0849, Accuracy: 97.01%
2024-02-18 10:07:53 - INFO - Epoch [7/10], Validation Loss: 0.8221, Validation Accuracy: 78.38%
2024-02-18 10:09:57 - INFO - Epoch [8/10], Loss: 0.0629, Accuracy: 97.87%
2024-02-18 10:09:59 - INFO - Epoch [8/10], Validation Loss: 0.9321, Validation Accuracy: 78.25%
2024-02-18 10:12:03 - INFO - Epoch [9/10], Loss: 0.0493, Accuracy: 98.35%
2024-02-18 10:12:06 - INFO - Epoch [9/10], Validation Loss: 0.9175, Validation Accuracy: 78.07%
2024-02-18 10:14:09 - INFO - Epoch [10/10], Loss: 0.0420, Accuracy: 98.57%
2024-02-18 10:14:12 - INFO - Epoch [10/10], Validation Loss: 1.0019, Validation Accuracy: 78.00%
2024-02-18 10:14:14 - INFO - Test Loss: 0.9838, Test Accuracy: 78.15%
2024-02-18 10:14:43 - INFO - ==========New Line==========
2024-02-18 10:14:43 - INFO - For 0 sample, the processed tweet content is: hey dear happy friday to you already had your rice is bowl for lunch
2024-02-18 10:14:43 - INFO - For 1 sample, the processed tweet content is: ughhh layin downnnn waiting for zeina to cook breakfast
2024-02-18 10:14:43 - INFO - For 2 sample, the processed tweet content is: i reckon he will play even if he is not but i know nothing it wont be the same without him
2024-02-18 10:14:43 - INFO - For 3 sample, the processed tweet content is: i know saw it on the news
2024-02-18 10:14:43 - INFO - For 4 sample, the processed tweet content is: very sad that has closed down one of the few web services that i have used for over years
2024-02-18 10:15:06 - INFO - Training and evaluating Logistic Regression...
2024-02-18 10:15:07 - INFO - Training and evaluating Multinomial Naive Bayes...
2024-02-18 10:15:07 - INFO - Accuracy for Multinomial Naive Bayes: 0.7671541761924149
2024-02-18 10:15:07 - INFO - Classification Report for Multinomial Naive Bayes:
              precision    recall  f1-score   support

           0       0.75      0.80      0.77     15963
           1       0.78      0.74      0.76     15968

    accuracy                           0.77     31931
   macro avg       0.77      0.77      0.77     31931
weighted avg       0.77      0.77      0.77     31931

2024-02-18 10:15:07 - INFO - --------------------------------------------------
2024-02-18 10:15:11 - INFO - Accuracy for Logistic Regression: 0.7816855093795998
2024-02-18 10:15:11 - INFO - Classification Report for Logistic Regression:
              precision    recall  f1-score   support

           0       0.79      0.77      0.78     15963
           1       0.77      0.80      0.79     15968

    accuracy                           0.78     31931
   macro avg       0.78      0.78      0.78     31931
weighted avg       0.78      0.78      0.78     31931

2024-02-18 10:15:11 - INFO - --------------------------------------------------
2024-02-18 10:15:12 - INFO - Number of Tokenized features are 40
2024-02-18 10:15:27 - INFO - embed_size:1024
2024-02-18 10:15:27 - INFO - hidden_size:1024
2024-02-18 10:15:27 - INFO - output_size:1
2024-02-18 10:15:27 - INFO - batch_size:8
2024-02-18 10:15:27 - INFO - learning_rate:0.0001
2024-02-18 10:17:59 - INFO - Epoch [1/10], Loss: 0.5144, Accuracy: 73.92%
2024-02-18 10:18:04 - INFO - Epoch [1/10], Validation Loss: 0.4506, Validation Accuracy: 78.78%
2024-02-18 10:20:36 - INFO - Epoch [2/10], Loss: 0.3959, Accuracy: 82.05%
2024-02-18 10:20:40 - INFO - Epoch [2/10], Validation Loss: 0.4380, Validation Accuracy: 79.84%
2024-02-18 10:23:12 - INFO - Epoch [3/10], Loss: 0.3049, Accuracy: 86.98%
2024-02-18 10:23:17 - INFO - Epoch [3/10], Validation Loss: 0.4515, Validation Accuracy: 79.96%
2024-02-18 10:25:47 - INFO - Epoch [4/10], Loss: 0.1927, Accuracy: 92.47%
2024-02-18 10:25:51 - INFO - Epoch [4/10], Validation Loss: 0.5647, Validation Accuracy: 79.32%
2024-02-18 10:28:21 - INFO - Epoch [5/10], Loss: 0.1068, Accuracy: 96.29%
2024-02-18 10:28:25 - INFO - Epoch [5/10], Validation Loss: 0.7565, Validation Accuracy: 77.78%
2024-02-18 10:30:55 - INFO - Epoch [6/10], Loss: 0.0679, Accuracy: 97.73%
2024-02-18 10:31:00 - INFO - Epoch [6/10], Validation Loss: 0.7971, Validation Accuracy: 78.77%
2024-02-18 10:33:29 - INFO - Epoch [7/10], Loss: 0.0508, Accuracy: 98.35%
2024-02-18 10:33:34 - INFO - Epoch [7/10], Validation Loss: 0.8879, Validation Accuracy: 78.47%
2024-02-18 10:36:03 - INFO - Epoch [8/10], Loss: 0.0406, Accuracy: 98.67%
2024-02-18 10:36:08 - INFO - Epoch [8/10], Validation Loss: 1.0154, Validation Accuracy: 77.91%
2024-02-18 10:38:38 - INFO - Epoch [9/10], Loss: 0.0349, Accuracy: 98.85%
2024-02-18 10:38:43 - INFO - Epoch [9/10], Validation Loss: 0.9933, Validation Accuracy: 78.69%
2024-02-18 10:41:13 - INFO - Epoch [10/10], Loss: 0.0305, Accuracy: 98.98%
2024-02-18 10:41:17 - INFO - Epoch [10/10], Validation Loss: 0.9949, Validation Accuracy: 78.21%
2024-02-18 10:41:22 - INFO - Test Loss: 0.9981, Test Accuracy: 78.46%
2024-02-18 10:41:38 - INFO - ==========New Line==========
2024-02-18 10:41:38 - INFO - For 0 sample, the processed tweet content is: hey dear happy friday to you already had your rice is bowl for lunch
2024-02-18 10:41:38 - INFO - For 1 sample, the processed tweet content is: ughhh layin downnnn waiting for zeina to cook breakfast
2024-02-18 10:41:38 - INFO - For 2 sample, the processed tweet content is: i reckon he will play even if he is not but i know nothing it wont be the same without him
2024-02-18 10:41:38 - INFO - For 3 sample, the processed tweet content is: i know saw it on the news
2024-02-18 10:41:38 - INFO - For 4 sample, the processed tweet content is: very sad that has closed down one of the few web services that i have used for over years
2024-02-18 10:42:01 - INFO - Training and evaluating Logistic Regression...
2024-02-18 10:42:01 - INFO - Training and evaluating Multinomial Naive Bayes...
2024-02-18 10:42:01 - INFO - Accuracy for Multinomial Naive Bayes: 0.7671541761924149
2024-02-18 10:42:02 - INFO - Classification Report for Multinomial Naive Bayes:
              precision    recall  f1-score   support

           0       0.75      0.80      0.77     15963
           1       0.78      0.74      0.76     15968

    accuracy                           0.77     31931
   macro avg       0.77      0.77      0.77     31931
weighted avg       0.77      0.77      0.77     31931

2024-02-18 10:42:02 - INFO - --------------------------------------------------
2024-02-18 10:42:05 - INFO - Accuracy for Logistic Regression: 0.7816855093795998
2024-02-18 10:42:06 - INFO - Classification Report for Logistic Regression:
              precision    recall  f1-score   support

           0       0.79      0.77      0.78     15963
           1       0.77      0.80      0.79     15968

    accuracy                           0.78     31931
   macro avg       0.78      0.78      0.78     31931
weighted avg       0.78      0.78      0.78     31931

2024-02-18 10:42:06 - INFO - --------------------------------------------------
2024-02-18 10:42:07 - INFO - Number of Tokenized features are 40
2024-02-18 10:42:07 - INFO - Tokenizer is bert-base-uncased
2024-02-18 10:42:22 - INFO - embed_size:1024
2024-02-18 10:42:22 - INFO - hidden_size:1024
2024-02-18 10:42:22 - INFO - output_size:1
2024-02-18 10:42:22 - INFO - batch_size:8
2024-02-18 10:42:22 - INFO - learning_rate:0.0001
2024-02-18 10:42:56 - INFO - ==========New Line==========
2024-02-18 10:42:56 - INFO - For 0 sample, the processed tweet content is: hey dear happy friday to you already had your rice is bowl for lunch
2024-02-18 10:42:56 - INFO - For 1 sample, the processed tweet content is: ughhh layin downnnn waiting for zeina to cook breakfast
2024-02-18 10:42:56 - INFO - For 2 sample, the processed tweet content is: i reckon he will play even if he is not but i know nothing it wont be the same without him
2024-02-18 10:42:56 - INFO - For 3 sample, the processed tweet content is: i know saw it on the news
2024-02-18 10:42:56 - INFO - For 4 sample, the processed tweet content is: very sad that has closed down one of the few web services that i have used for over years
2024-02-18 10:43:19 - INFO - Training and evaluating Logistic Regression...
2024-02-18 10:43:19 - INFO - Training and evaluating Multinomial Naive Bayes...
2024-02-18 10:43:19 - INFO - Accuracy for Multinomial Naive Bayes: 0.7671541761924149
2024-02-18 10:43:20 - INFO - Classification Report for Multinomial Naive Bayes:
              precision    recall  f1-score   support

           0       0.75      0.80      0.77     15963
           1       0.78      0.74      0.76     15968

    accuracy                           0.77     31931
   macro avg       0.77      0.77      0.77     31931
weighted avg       0.77      0.77      0.77     31931

2024-02-18 10:43:20 - INFO - --------------------------------------------------
2024-02-18 10:43:23 - INFO - Accuracy for Logistic Regression: 0.7816855093795998
2024-02-18 10:43:24 - INFO - Classification Report for Logistic Regression:
              precision    recall  f1-score   support

           0       0.79      0.77      0.78     15963
           1       0.77      0.80      0.79     15968

    accuracy                           0.78     31931
   macro avg       0.78      0.78      0.78     31931
weighted avg       0.78      0.78      0.78     31931

2024-02-18 10:43:24 - INFO - --------------------------------------------------
2024-02-18 10:43:24 - INFO - Number of Tokenized features are 40
2024-02-18 10:43:27 - INFO - Tokenizer is gpt2-large
2024-02-18 10:46:22 - INFO - ==========New Line==========
2024-02-18 10:46:22 - INFO - For 0 sample, the processed tweet content is: hey dear happy friday to you already had your rice is bowl for lunch
2024-02-18 10:46:22 - INFO - For 1 sample, the processed tweet content is: ughhh layin downnnn waiting for zeina to cook breakfast
2024-02-18 10:46:22 - INFO - For 2 sample, the processed tweet content is: i reckon he will play even if he is not but i know nothing it wont be the same without him
2024-02-18 10:46:22 - INFO - For 3 sample, the processed tweet content is: i know saw it on the news
2024-02-18 10:46:22 - INFO - For 4 sample, the processed tweet content is: very sad that has closed down one of the few web services that i have used for over years
2024-02-18 10:46:45 - INFO - Training and evaluating Logistic Regression...
2024-02-18 10:46:45 - INFO - Training and evaluating Multinomial Naive Bayes...
2024-02-18 10:46:45 - INFO - Accuracy for Multinomial Naive Bayes: 0.7671541761924149
2024-02-18 10:46:46 - INFO - Classification Report for Multinomial Naive Bayes:
              precision    recall  f1-score   support

           0       0.75      0.80      0.77     15963
           1       0.78      0.74      0.76     15968

    accuracy                           0.77     31931
   macro avg       0.77      0.77      0.77     31931
weighted avg       0.77      0.77      0.77     31931

2024-02-18 10:46:46 - INFO - --------------------------------------------------
2024-02-18 10:46:49 - INFO - Accuracy for Logistic Regression: 0.7816855093795998
2024-02-18 10:46:50 - INFO - Classification Report for Logistic Regression:
              precision    recall  f1-score   support

           0       0.79      0.77      0.78     15963
           1       0.77      0.80      0.79     15968

    accuracy                           0.78     31931
   macro avg       0.78      0.78      0.78     31931
weighted avg       0.78      0.78      0.78     31931

2024-02-18 10:46:50 - INFO - --------------------------------------------------
2024-02-18 10:46:50 - INFO - Number of Tokenized features are 40
2024-02-18 10:46:51 - INFO - Tokenizer is gpt2-large
2024-02-18 10:47:04 - INFO - embed_size:1024
2024-02-18 10:47:04 - INFO - hidden_size:1024
2024-02-18 10:47:04 - INFO - output_size:1
2024-02-18 10:47:04 - INFO - batch_size:8
2024-02-18 10:47:04 - INFO - learning_rate:0.0001
2024-02-18 10:56:25 - INFO - ==========New Line==========
2024-02-18 10:56:25 - INFO - For 0 sample, the processed tweet content is: hey dear happy friday to you already had your rice is bowl for lunch
2024-02-18 10:56:25 - INFO - For 1 sample, the processed tweet content is: ughhh layin downnnn waiting for zeina to cook breakfast
2024-02-18 10:56:25 - INFO - For 2 sample, the processed tweet content is: i reckon he will play even if he is not but i know nothing it wont be the same without him
2024-02-18 10:56:25 - INFO - For 3 sample, the processed tweet content is: i know saw it on the news
2024-02-18 10:56:25 - INFO - For 4 sample, the processed tweet content is: very sad that has closed down one of the few web services that i have used for over years
2024-02-18 10:56:48 - INFO - Training and evaluating Logistic Regression...
2024-02-18 10:56:48 - INFO - Training and evaluating Multinomial Naive Bayes...
2024-02-18 10:56:48 - INFO - Accuracy for Multinomial Naive Bayes: 0.7671541761924149
2024-02-18 10:56:49 - INFO - Classification Report for Multinomial Naive Bayes:
              precision    recall  f1-score   support

           0       0.75      0.80      0.77     15963
           1       0.78      0.74      0.76     15968

    accuracy                           0.77     31931
   macro avg       0.77      0.77      0.77     31931
weighted avg       0.77      0.77      0.77     31931

2024-02-18 10:56:49 - INFO - --------------------------------------------------
2024-02-18 10:56:52 - INFO - Accuracy for Logistic Regression: 0.7816855093795998
2024-02-18 10:56:52 - INFO - Classification Report for Logistic Regression:
              precision    recall  f1-score   support

           0       0.79      0.77      0.78     15963
           1       0.77      0.80      0.79     15968

    accuracy                           0.78     31931
   macro avg       0.78      0.78      0.78     31931
weighted avg       0.78      0.78      0.78     31931

2024-02-18 10:56:52 - INFO - --------------------------------------------------
2024-02-18 10:56:53 - INFO - Number of Tokenized features are 40
2024-02-18 10:56:54 - INFO - Tokenizer is gpt2-large
2024-02-18 10:57:06 - INFO - embed_size:1024
2024-02-18 10:57:06 - INFO - hidden_size:1024
2024-02-18 10:57:06 - INFO - output_size:1
2024-02-18 10:57:06 - INFO - batch_size:8
2024-02-18 10:57:06 - INFO - learning_rate:0.0001
2024-02-18 11:00:11 - INFO - Epoch [1/10], Loss: 0.5330, Accuracy: 72.68%
2024-02-18 11:00:16 - INFO - Epoch [1/10], Validation Loss: 0.4697, Validation Accuracy: 77.66%
2024-02-18 11:03:21 - INFO - Epoch [2/10], Loss: 0.4127, Accuracy: 81.22%
2024-02-18 11:03:25 - INFO - Epoch [2/10], Validation Loss: 0.4489, Validation Accuracy: 78.95%
2024-02-18 11:06:31 - INFO - Epoch [3/10], Loss: 0.3175, Accuracy: 86.47%
2024-02-18 11:06:35 - INFO - Epoch [3/10], Validation Loss: 0.4747, Validation Accuracy: 78.53%
2024-02-18 11:09:37 - INFO - Epoch [4/10], Loss: 0.1977, Accuracy: 92.30%
2024-02-18 11:09:42 - INFO - Epoch [4/10], Validation Loss: 0.5849, Validation Accuracy: 78.53%
2024-02-18 11:12:44 - INFO - Epoch [5/10], Loss: 0.1026, Accuracy: 96.32%
2024-02-18 11:12:48 - INFO - Epoch [5/10], Validation Loss: 0.7262, Validation Accuracy: 77.63%
2024-02-18 11:13:45 - INFO - ==========New Line==========
2024-02-18 11:13:45 - INFO - For 0 sample, the processed tweet content is: hey dear happy friday to you already had your rice is bowl for lunch
2024-02-18 11:13:45 - INFO - For 1 sample, the processed tweet content is: ughhh layin downnnn waiting for zeina to cook breakfast
2024-02-18 11:13:45 - INFO - For 2 sample, the processed tweet content is: i reckon he will play even if he is not but i know nothing it wont be the same without him
2024-02-18 11:13:45 - INFO - For 3 sample, the processed tweet content is: i know saw it on the news
2024-02-18 11:13:45 - INFO - For 4 sample, the processed tweet content is: very sad that has closed down one of the few web services that i have used for over years
2024-02-18 11:14:08 - INFO - Training and evaluating Logistic Regression...
2024-02-18 11:14:08 - INFO - Training and evaluating Multinomial Naive Bayes...
2024-02-18 11:14:08 - INFO - Accuracy for Multinomial Naive Bayes: 0.7671541761924149
2024-02-18 11:14:09 - INFO - Classification Report for Multinomial Naive Bayes:
              precision    recall  f1-score   support

           0       0.75      0.80      0.77     15963
           1       0.78      0.74      0.76     15968

    accuracy                           0.77     31931
   macro avg       0.77      0.77      0.77     31931
weighted avg       0.77      0.77      0.77     31931

2024-02-18 11:14:09 - INFO - --------------------------------------------------
2024-02-18 11:14:12 - INFO - Accuracy for Logistic Regression: 0.7816855093795998
2024-02-18 11:14:13 - INFO - Classification Report for Logistic Regression:
              precision    recall  f1-score   support

           0       0.79      0.77      0.78     15963
           1       0.77      0.80      0.79     15968

    accuracy                           0.78     31931
   macro avg       0.78      0.78      0.78     31931
weighted avg       0.78      0.78      0.78     31931

2024-02-18 11:14:13 - INFO - --------------------------------------------------
2024-02-18 11:14:13 - INFO - Number of Tokenized features are 40
2024-02-18 11:14:14 - INFO - Tokenizer is gpt2-large
2024-02-18 11:14:26 - INFO - embed_size:512
2024-02-18 11:14:26 - INFO - hidden_size:1024
2024-02-18 11:14:26 - INFO - output_size:1
2024-02-18 11:14:26 - INFO - batch_size:8
2024-02-18 11:14:26 - INFO - learning_rate:0.001
2024-02-18 11:16:41 - INFO - Epoch [1/10], Loss: 0.5983, Accuracy: 65.01%
2024-02-18 11:16:46 - INFO - Epoch [1/10], Validation Loss: 0.4965, Validation Accuracy: 76.10%
2024-02-18 11:19:00 - INFO - Epoch [2/10], Loss: 0.4595, Accuracy: 78.60%
2024-02-18 11:19:04 - INFO - Epoch [2/10], Validation Loss: 0.4705, Validation Accuracy: 77.88%
2024-02-18 11:21:17 - INFO - Epoch [3/10], Loss: 0.4118, Accuracy: 81.40%
2024-02-18 11:21:21 - INFO - Epoch [3/10], Validation Loss: 0.4678, Validation Accuracy: 78.50%
2024-02-18 11:23:35 - INFO - Epoch [4/10], Loss: 0.3796, Accuracy: 83.35%
2024-02-18 11:23:39 - INFO - Epoch [4/10], Validation Loss: 0.4758, Validation Accuracy: 78.30%
2024-02-18 11:25:51 - INFO - ==========New Line==========
2024-02-18 11:25:51 - INFO - For 0 sample, the processed tweet content is: hey dear happy friday to you already had your rice is bowl for lunch
2024-02-18 11:25:51 - INFO - For 1 sample, the processed tweet content is: ughhh layin downnnn waiting for zeina to cook breakfast
2024-02-18 11:25:51 - INFO - For 2 sample, the processed tweet content is: i reckon he will play even if he is not but i know nothing it wont be the same without him
2024-02-18 11:25:51 - INFO - For 3 sample, the processed tweet content is: i know saw it on the news
2024-02-18 11:25:51 - INFO - For 4 sample, the processed tweet content is: very sad that has closed down one of the few web services that i have used for over years
2024-02-18 11:26:14 - INFO - Training and evaluating Logistic Regression...
2024-02-18 11:26:14 - INFO - Training and evaluating Multinomial Naive Bayes...
2024-02-18 11:26:15 - INFO - Accuracy for Multinomial Naive Bayes: 0.7671541761924149
2024-02-18 11:26:15 - INFO - Classification Report for Multinomial Naive Bayes:
              precision    recall  f1-score   support

           0       0.75      0.80      0.77     15963
           1       0.78      0.74      0.76     15968

    accuracy                           0.77     31931
   macro avg       0.77      0.77      0.77     31931
weighted avg       0.77      0.77      0.77     31931

2024-02-18 11:26:15 - INFO - --------------------------------------------------
2024-02-18 11:26:18 - INFO - Accuracy for Logistic Regression: 0.7816855093795998
2024-02-18 11:26:19 - INFO - Classification Report for Logistic Regression:
              precision    recall  f1-score   support

           0       0.79      0.77      0.78     15963
           1       0.77      0.80      0.79     15968

    accuracy                           0.78     31931
   macro avg       0.78      0.78      0.78     31931
weighted avg       0.78      0.78      0.78     31931

2024-02-18 11:26:19 - INFO - --------------------------------------------------
2024-02-18 11:26:19 - INFO - Number of Tokenized features are 40
2024-02-18 11:26:21 - INFO - Tokenizer is gpt2-large
2024-02-18 11:26:33 - INFO - embed_size:1024
2024-02-18 11:26:33 - INFO - hidden_size:1024
2024-02-18 11:26:33 - INFO - output_size:1
2024-02-18 11:26:33 - INFO - batch_size:16
2024-02-18 11:26:33 - INFO - learning_rate:0.001
2024-02-18 11:28:24 - INFO - Epoch [1/10], Loss: 0.5862, Accuracy: 67.13%
2024-02-18 11:28:27 - INFO - Epoch [1/10], Validation Loss: 0.4995, Validation Accuracy: 76.12%
2024-02-18 11:30:17 - INFO - Epoch [2/10], Loss: 0.4547, Accuracy: 79.33%
2024-02-18 11:30:20 - INFO - Epoch [2/10], Validation Loss: 0.4793, Validation Accuracy: 77.78%
2024-02-18 11:32:10 - INFO - Epoch [3/10], Loss: 0.4099, Accuracy: 81.76%
2024-02-18 11:32:13 - INFO - Epoch [3/10], Validation Loss: 0.4738, Validation Accuracy: 78.10%
2024-02-18 11:34:03 - INFO - Epoch [4/10], Loss: 0.3636, Accuracy: 84.38%
2024-02-18 11:34:07 - INFO - Epoch [4/10], Validation Loss: 0.4772, Validation Accuracy: 78.13%
2024-02-18 11:35:54 - INFO - Epoch [5/10], Loss: 0.3278, Accuracy: 86.10%
2024-02-18 11:35:57 - INFO - Epoch [5/10], Validation Loss: 0.4959, Validation Accuracy: 78.07%
2024-02-18 11:37:45 - INFO - Epoch [6/10], Loss: 0.2980, Accuracy: 87.59%
2024-02-18 11:37:48 - INFO - Epoch [6/10], Validation Loss: 0.5197, Validation Accuracy: 77.95%
2024-02-18 11:39:47 - INFO - ==========New Line==========
2024-02-18 11:39:47 - INFO - For 0 sample, the processed tweet content is: hey dear happy friday to you already had your rice is bowl for lunch
2024-02-18 11:39:47 - INFO - For 1 sample, the processed tweet content is: ughhh layin downnnn waiting for zeina to cook breakfast
2024-02-18 11:39:47 - INFO - For 2 sample, the processed tweet content is: i reckon he will play even if he is not but i know nothing it wont be the same without him
2024-02-18 11:39:47 - INFO - For 3 sample, the processed tweet content is: i know saw it on the news
2024-02-18 11:39:47 - INFO - For 4 sample, the processed tweet content is: very sad that has closed down one of the few web services that i have used for over years
2024-02-18 11:40:10 - INFO - Training and evaluating Logistic Regression...
2024-02-18 11:40:10 - INFO - Training and evaluating Multinomial Naive Bayes...
2024-02-18 11:40:10 - INFO - Accuracy for Multinomial Naive Bayes: 0.7671541761924149
2024-02-18 11:40:11 - INFO - Classification Report for Multinomial Naive Bayes:
              precision    recall  f1-score   support

           0       0.75      0.80      0.77     15963
           1       0.78      0.74      0.76     15968

    accuracy                           0.77     31931
   macro avg       0.77      0.77      0.77     31931
weighted avg       0.77      0.77      0.77     31931

2024-02-18 11:40:11 - INFO - --------------------------------------------------
2024-02-18 11:40:14 - INFO - Accuracy for Logistic Regression: 0.7816855093795998
2024-02-18 11:40:15 - INFO - Classification Report for Logistic Regression:
              precision    recall  f1-score   support

           0       0.79      0.77      0.78     15963
           1       0.77      0.80      0.79     15968

    accuracy                           0.78     31931
   macro avg       0.78      0.78      0.78     31931
weighted avg       0.78      0.78      0.78     31931

2024-02-18 11:40:15 - INFO - --------------------------------------------------
2024-02-18 11:40:15 - INFO - Number of Tokenized features are 40
2024-02-18 11:40:16 - INFO - Tokenizer is bert-base-uncased
2024-02-18 11:40:30 - INFO - embed_size:512
2024-02-18 11:40:30 - INFO - hidden_size:512
2024-02-18 11:40:30 - INFO - output_size:1
2024-02-18 11:40:30 - INFO - batch_size:16
2024-02-18 11:40:30 - INFO - learning_rate:0.001
2024-02-18 11:41:35 - INFO - Epoch [1/10], Loss: 0.5473, Accuracy: 70.70%
2024-02-18 11:41:37 - INFO - Epoch [1/10], Validation Loss: 0.4658, Validation Accuracy: 78.40%
2024-02-18 11:42:40 - INFO - Epoch [2/10], Loss: 0.4193, Accuracy: 80.92%
2024-02-18 11:42:42 - INFO - Epoch [2/10], Validation Loss: 0.4496, Validation Accuracy: 79.15%
2024-02-18 11:43:45 - INFO - Epoch [3/10], Loss: 0.3591, Accuracy: 84.38%
2024-02-18 11:43:47 - INFO - Epoch [3/10], Validation Loss: 0.4562, Validation Accuracy: 78.78%
2024-02-18 11:44:50 - INFO - Epoch [4/10], Loss: 0.3022, Accuracy: 87.35%
2024-02-18 11:44:52 - INFO - Epoch [4/10], Validation Loss: 0.4972, Validation Accuracy: 79.00%
2024-02-18 11:45:54 - INFO - Epoch [5/10], Loss: 0.2550, Accuracy: 89.58%
2024-02-18 11:45:56 - INFO - Epoch [5/10], Validation Loss: 0.5202, Validation Accuracy: 78.51%
2024-02-18 11:46:59 - INFO - Epoch [6/10], Loss: 0.2178, Accuracy: 91.33%
2024-02-18 11:47:00 - INFO - Epoch [6/10], Validation Loss: 0.5645, Validation Accuracy: 78.21%
2024-02-18 11:48:03 - INFO - Epoch [7/10], Loss: 0.1904, Accuracy: 92.53%
2024-02-18 11:48:05 - INFO - Epoch [7/10], Validation Loss: 0.5990, Validation Accuracy: 77.92%
2024-02-18 11:49:07 - INFO - Epoch [8/10], Loss: 0.1724, Accuracy: 93.23%
2024-02-18 11:49:09 - INFO - Epoch [8/10], Validation Loss: 0.6247, Validation Accuracy: 77.83%
2024-02-18 11:50:12 - INFO - Epoch [9/10], Loss: 0.1592, Accuracy: 93.80%
2024-02-18 11:50:13 - INFO - Epoch [9/10], Validation Loss: 0.6771, Validation Accuracy: 77.17%
2024-02-18 11:51:17 - INFO - Epoch [10/10], Loss: 0.1493, Accuracy: 94.23%
2024-02-18 11:51:18 - INFO - Epoch [10/10], Validation Loss: 0.7095, Validation Accuracy: 77.44%
2024-02-18 11:51:20 - INFO - Test Loss: 0.6809, Test Accuracy: 77.76%
2024-02-18 11:52:49 - INFO - ==========New Line==========
2024-02-18 11:52:49 - INFO - For 0 sample, the processed tweet content is: hey dear happy friday to you already had your rice is bowl for lunch
2024-02-18 11:52:49 - INFO - For 1 sample, the processed tweet content is: ughhh layin downnnn waiting for zeina to cook breakfast
2024-02-18 11:52:49 - INFO - For 2 sample, the processed tweet content is: i reckon he will play even if he is not but i know nothing it wont be the same without him
2024-02-18 11:52:49 - INFO - For 3 sample, the processed tweet content is: i know saw it on the news
2024-02-18 11:52:49 - INFO - For 4 sample, the processed tweet content is: very sad that has closed down one of the few web services that i have used for over years
2024-02-18 11:53:12 - INFO - Training and evaluating Logistic Regression...
2024-02-18 11:53:12 - INFO - Training and evaluating Multinomial Naive Bayes...
2024-02-18 11:53:12 - INFO - Accuracy for Multinomial Naive Bayes: 0.7671541761924149
2024-02-18 11:53:13 - INFO - Classification Report for Multinomial Naive Bayes:
              precision    recall  f1-score   support

           0       0.75      0.80      0.77     15963
           1       0.78      0.74      0.76     15968

    accuracy                           0.77     31931
   macro avg       0.77      0.77      0.77     31931
weighted avg       0.77      0.77      0.77     31931

2024-02-18 11:53:13 - INFO - --------------------------------------------------
2024-02-18 11:53:16 - INFO - Accuracy for Logistic Regression: 0.7816855093795998
2024-02-18 11:53:17 - INFO - Classification Report for Logistic Regression:
              precision    recall  f1-score   support

           0       0.79      0.77      0.78     15963
           1       0.77      0.80      0.79     15968

    accuracy                           0.78     31931
   macro avg       0.78      0.78      0.78     31931
weighted avg       0.78      0.78      0.78     31931

2024-02-18 11:53:17 - INFO - --------------------------------------------------
2024-02-18 11:53:17 - INFO - Number of Tokenized features are 40
2024-02-18 11:53:18 - INFO - Tokenizer is gpt2-large
2024-02-18 11:53:31 - INFO - embed_size:512
2024-02-18 11:53:31 - INFO - hidden_size:512
2024-02-18 11:53:31 - INFO - output_size:1
2024-02-18 11:53:31 - INFO - batch_size:32
2024-02-18 11:53:31 - INFO - learning_rate:0.0001
2024-02-18 11:54:08 - INFO - Epoch [1/10], Loss: 0.6075, Accuracy: 63.61%
2024-02-18 11:54:09 - INFO - Epoch [1/10], Validation Loss: 0.5047, Validation Accuracy: 75.43%
2024-02-18 11:54:45 - INFO - Epoch [2/10], Loss: 0.4637, Accuracy: 78.20%
2024-02-18 11:54:46 - INFO - Epoch [2/10], Validation Loss: 0.4770, Validation Accuracy: 77.56%
2024-02-18 11:55:21 - INFO - Epoch [3/10], Loss: 0.4089, Accuracy: 81.49%
2024-02-18 11:55:22 - INFO - Epoch [3/10], Validation Loss: 0.4590, Validation Accuracy: 78.60%
2024-02-18 11:55:57 - INFO - Epoch [4/10], Loss: 0.3573, Accuracy: 84.36%
2024-02-18 11:55:58 - INFO - Epoch [4/10], Validation Loss: 0.4779, Validation Accuracy: 78.76%
2024-02-18 11:56:33 - INFO - Epoch [5/10], Loss: 0.2980, Accuracy: 87.47%
2024-02-18 11:56:34 - INFO - Epoch [5/10], Validation Loss: 0.5197, Validation Accuracy: 78.82%
2024-02-18 11:57:08 - INFO - Epoch [6/10], Loss: 0.2314, Accuracy: 90.77%
2024-02-18 11:57:09 - INFO - Epoch [6/10], Validation Loss: 0.5823, Validation Accuracy: 77.17%
2024-02-18 11:57:42 - INFO - Epoch [7/10], Loss: 0.1689, Accuracy: 93.63%
2024-02-18 11:57:43 - INFO - Epoch [7/10], Validation Loss: 0.6460, Validation Accuracy: 77.64%
2024-02-18 11:58:18 - INFO - Epoch [8/10], Loss: 0.1202, Accuracy: 95.61%
2024-02-18 11:58:19 - INFO - Epoch [8/10], Validation Loss: 0.7913, Validation Accuracy: 76.87%
2024-02-18 11:58:52 - INFO - Epoch [9/10], Loss: 0.0894, Accuracy: 96.92%
2024-02-18 11:58:53 - INFO - Epoch [9/10], Validation Loss: 0.8502, Validation Accuracy: 76.91%
2024-02-18 11:59:28 - INFO - Epoch [10/10], Loss: 0.0704, Accuracy: 97.57%
2024-02-18 11:59:29 - INFO - Epoch [10/10], Validation Loss: 0.9644, Validation Accuracy: 76.99%
2024-02-18 11:59:30 - INFO - Test Loss: 0.9650, Test Accuracy: 76.74%
2024-02-18 12:00:02 - INFO - ==========New Line==========
2024-02-18 12:00:02 - INFO - For 0 sample, the processed tweet content is: hey dear happy friday to you already had your rice is bowl for lunch
2024-02-18 12:00:02 - INFO - For 1 sample, the processed tweet content is: ughhh layin downnnn waiting for zeina to cook breakfast
2024-02-18 12:00:02 - INFO - For 2 sample, the processed tweet content is: i reckon he will play even if he is not but i know nothing it wont be the same without him
2024-02-18 12:00:02 - INFO - For 3 sample, the processed tweet content is: i know saw it on the news
2024-02-18 12:00:02 - INFO - For 4 sample, the processed tweet content is: very sad that has closed down one of the few web services that i have used for over years
2024-02-18 12:00:25 - INFO - Training and evaluating Logistic Regression...
2024-02-18 12:00:26 - INFO - Training and evaluating Multinomial Naive Bayes...
2024-02-18 12:00:26 - INFO - Accuracy for Multinomial Naive Bayes: 0.7707556919607904
2024-02-18 12:00:26 - INFO - Classification Report for Multinomial Naive Bayes:
              precision    recall  f1-score   support

           0       0.75      0.81      0.78     15981
           1       0.79      0.73      0.76     15950

    accuracy                           0.77     31931
   macro avg       0.77      0.77      0.77     31931
weighted avg       0.77      0.77      0.77     31931

2024-02-18 12:00:26 - INFO - --------------------------------------------------
2024-02-18 12:00:30 - INFO - Accuracy for Logistic Regression: 0.7841595941248317
2024-02-18 12:00:30 - INFO - Classification Report for Logistic Regression:
              precision    recall  f1-score   support

           0       0.79      0.77      0.78     15981
           1       0.78      0.80      0.79     15950

    accuracy                           0.78     31931
   macro avg       0.78      0.78      0.78     31931
weighted avg       0.78      0.78      0.78     31931

2024-02-18 12:00:30 - INFO - --------------------------------------------------
2024-02-18 12:00:31 - INFO - Number of Tokenized features are 40
2024-02-18 12:00:32 - INFO - Tokenizer is gpt2-large
2024-02-18 12:00:44 - INFO - embed_size:512
2024-02-18 12:00:44 - INFO - hidden_size:512
2024-02-18 12:00:44 - INFO - output_size:1
2024-02-18 12:00:44 - INFO - batch_size:16
2024-02-18 12:00:44 - INFO - learning_rate:0.0001
2024-02-18 12:01:51 - INFO - Epoch [1/10], Loss: 0.5867, Accuracy: 66.77%
2024-02-18 12:01:53 - INFO - Epoch [1/10], Validation Loss: 0.4904, Validation Accuracy: 76.15%
2024-02-18 12:02:59 - INFO - Epoch [2/10], Loss: 0.4528, Accuracy: 79.00%
2024-02-18 12:03:00 - INFO - Epoch [2/10], Validation Loss: 0.4644, Validation Accuracy: 78.01%
2024-02-18 12:04:06 - INFO - Epoch [3/10], Loss: 0.3939, Accuracy: 82.33%
2024-02-18 12:04:08 - INFO - Epoch [3/10], Validation Loss: 0.4502, Validation Accuracy: 78.75%
2024-02-18 12:05:13 - INFO - Epoch [4/10], Loss: 0.3335, Accuracy: 85.61%
2024-02-18 12:05:15 - INFO - Epoch [4/10], Validation Loss: 0.4724, Validation Accuracy: 78.75%
2024-02-18 12:08:08 - INFO - ==========New Line==========
2024-02-18 12:08:08 - INFO - For 0 sample, the processed tweet content is: hey dear happy friday to you already had your rice is bowl for lunch
2024-02-18 12:08:08 - INFO - For 1 sample, the processed tweet content is: ughhh layin downnnn waiting for zeina to cook breakfast
2024-02-18 12:08:08 - INFO - For 2 sample, the processed tweet content is: i reckon he will play even if he is not but i know nothing it wont be the same without him
2024-02-18 12:08:08 - INFO - For 3 sample, the processed tweet content is: i know saw it on the news
2024-02-18 12:08:08 - INFO - For 4 sample, the processed tweet content is: very sad that has closed down one of the few web services that i have used for over years
2024-02-18 12:08:31 - INFO - Training and evaluating Logistic Regression...
2024-02-18 12:08:32 - INFO - Training and evaluating Multinomial Naive Bayes...
2024-02-18 12:08:32 - INFO - Accuracy for Multinomial Naive Bayes: 0.7707556919607904
2024-02-18 12:08:32 - INFO - Training and evaluating Random Forest...
2024-02-18 12:08:32 - INFO - Training and evaluating XGBoost...
2024-02-18 12:08:33 - INFO - Classification Report for Multinomial Naive Bayes:
              precision    recall  f1-score   support

           0       0.75      0.81      0.78     15981
           1       0.79      0.73      0.76     15950

    accuracy                           0.77     31931
   macro avg       0.77      0.77      0.77     31931
weighted avg       0.77      0.77      0.77     31931

2024-02-18 12:08:33 - INFO - --------------------------------------------------
2024-02-18 12:08:39 - INFO - Accuracy for XGBoost: 0.7617049262472205
2024-02-18 12:08:40 - INFO - Classification Report for XGBoost:
              precision    recall  f1-score   support

           0       0.79      0.71      0.75     15981
           1       0.74      0.81      0.77     15950

    accuracy                           0.76     31931
   macro avg       0.76      0.76      0.76     31931
weighted avg       0.76      0.76      0.76     31931

2024-02-18 12:08:40 - INFO - --------------------------------------------------
2024-02-18 12:08:44 - INFO - Accuracy for Logistic Regression: 0.7841595941248317
2024-02-18 12:08:44 - INFO - Classification Report for Logistic Regression:
              precision    recall  f1-score   support

           0       0.79      0.77      0.78     15981
           1       0.78      0.80      0.79     15950

    accuracy                           0.78     31931
   macro avg       0.78      0.78      0.78     31931
weighted avg       0.78      0.78      0.78     31931

2024-02-18 12:08:44 - INFO - --------------------------------------------------
2024-02-18 12:29:21 - INFO - Accuracy for Random Forest: 0.778647709122796
2024-02-18 12:29:21 - INFO - Classification Report for Random Forest:
              precision    recall  f1-score   support

           0       0.76      0.81      0.78     15981
           1       0.79      0.75      0.77     15950

    accuracy                           0.78     31931
   macro avg       0.78      0.78      0.78     31931
weighted avg       0.78      0.78      0.78     31931

2024-02-18 12:29:21 - INFO - --------------------------------------------------
2024-02-18 12:29:22 - INFO - Number of Tokenized features are 40
2024-02-18 12:29:22 - INFO - Tokenizer is bert-base-uncased
2024-02-18 12:29:37 - INFO - embed_size:512
2024-02-18 12:29:37 - INFO - hidden_size:1024
2024-02-18 12:29:37 - INFO - output_size:1
2024-02-18 12:29:37 - INFO - batch_size:16
2024-02-18 12:29:37 - INFO - learning_rate:0.0001
2024-02-18 12:30:52 - INFO - Epoch [1/10], Loss: 0.5721, Accuracy: 67.93%
2024-02-18 12:30:55 - INFO - Epoch [1/10], Validation Loss: 0.4845, Validation Accuracy: 77.02%
2024-02-18 12:32:08 - INFO - Epoch [2/10], Loss: 0.4417, Accuracy: 79.48%
2024-02-18 12:32:12 - INFO - Epoch [2/10], Validation Loss: 0.4481, Validation Accuracy: 78.78%
2024-02-18 12:33:25 - INFO - Epoch [3/10], Loss: 0.3788, Accuracy: 83.05%
2024-02-18 12:33:28 - INFO - Epoch [3/10], Validation Loss: 0.4552, Validation Accuracy: 78.44%
2024-02-18 12:34:40 - INFO - Epoch [4/10], Loss: 0.3059, Accuracy: 86.95%
2024-02-18 12:34:44 - INFO - Epoch [4/10], Validation Loss: 0.4615, Validation Accuracy: 79.30%
2024-02-18 12:35:56 - INFO - Epoch [5/10], Loss: 0.2132, Accuracy: 91.60%
2024-02-18 12:35:59 - INFO - Epoch [5/10], Validation Loss: 0.5706, Validation Accuracy: 78.50%
2024-02-18 12:37:14 - INFO - ==========New Line==========
2024-02-18 12:37:14 - INFO - For 0 sample, the processed tweet content is: hey dear happy friday to you already had your rice is bowl for lunch
2024-02-18 12:37:14 - INFO - For 1 sample, the processed tweet content is: ughhh layin downnnn waiting for zeina to cook breakfast
2024-02-18 12:37:14 - INFO - For 2 sample, the processed tweet content is: i reckon he will play even if he is not but i know nothing it wont be the same without him
2024-02-18 12:37:14 - INFO - For 3 sample, the processed tweet content is: i know saw it on the news
2024-02-18 12:37:14 - INFO - For 4 sample, the processed tweet content is: very sad that has closed down one of the few web services that i have used for over years
2024-02-18 12:37:37 - INFO - Training and evaluating Logistic Regression...
2024-02-18 12:37:37 - INFO - Training and evaluating Multinomial Naive Bayes...
2024-02-18 12:37:37 - INFO - Accuracy for Multinomial Naive Bayes: 0.7707556919607904
2024-02-18 12:37:37 - INFO - Training and evaluating XGBoost...
2024-02-18 12:37:38 - INFO - Classification Report for Multinomial Naive Bayes:
              precision    recall  f1-score   support

           0       0.75      0.81      0.78     15981
           1       0.79      0.73      0.76     15950

    accuracy                           0.77     31931
   macro avg       0.77      0.77      0.77     31931
weighted avg       0.77      0.77      0.77     31931

2024-02-18 12:37:38 - INFO - --------------------------------------------------
2024-02-18 12:37:40 - INFO - Accuracy for XGBoost: 0.7046130719363628
2024-02-18 12:37:41 - INFO - Classification Report for XGBoost:
              precision    recall  f1-score   support

           0       0.74      0.62      0.68     15981
           1       0.68      0.79      0.73     15950

    accuracy                           0.70     31931
   macro avg       0.71      0.70      0.70     31931
weighted avg       0.71      0.70      0.70     31931

2024-02-18 12:37:41 - INFO - --------------------------------------------------
2024-02-18 12:37:43 - INFO - Accuracy for Logistic Regression: 0.7841595941248317
2024-02-18 12:37:44 - INFO - Classification Report for Logistic Regression:
              precision    recall  f1-score   support

           0       0.79      0.77      0.78     15981
           1       0.78      0.80      0.79     15950

    accuracy                           0.78     31931
   macro avg       0.78      0.78      0.78     31931
weighted avg       0.78      0.78      0.78     31931

2024-02-18 12:37:44 - INFO - --------------------------------------------------
2024-02-18 12:37:44 - INFO - Number of Tokenized features are 40
2024-02-18 12:37:45 - INFO - Tokenizer is bert-base-uncased
2024-02-18 12:37:59 - INFO - embed_size:1024
2024-02-18 12:37:59 - INFO - hidden_size:1024
2024-02-18 12:37:59 - INFO - output_size:1
2024-02-18 12:37:59 - INFO - batch_size:8
2024-02-18 12:37:59 - INFO - learning_rate:0.0001
2024-02-18 12:40:33 - INFO - Epoch [1/10], Loss: 0.5160, Accuracy: 73.82%
2024-02-18 12:40:37 - INFO - Epoch [1/10], Validation Loss: 0.4519, Validation Accuracy: 79.00%
2024-02-18 12:43:10 - INFO - Epoch [2/10], Loss: 0.3984, Accuracy: 81.95%
2024-02-18 12:43:15 - INFO - Epoch [2/10], Validation Loss: 0.4347, Validation Accuracy: 80.08%
2024-02-18 12:45:47 - INFO - Epoch [3/10], Loss: 0.3062, Accuracy: 86.82%
2024-02-18 12:45:52 - INFO - Epoch [3/10], Validation Loss: 0.4516, Validation Accuracy: 79.81%
2024-02-18 12:48:22 - INFO - Epoch [4/10], Loss: 0.1914, Accuracy: 92.48%
2024-02-18 12:48:26 - INFO - Epoch [4/10], Validation Loss: 0.5446, Validation Accuracy: 78.69%
2024-02-18 12:50:57 - INFO - Epoch [5/10], Loss: 0.1019, Accuracy: 96.33%
2024-02-18 12:51:01 - INFO - Epoch [5/10], Validation Loss: 0.6953, Validation Accuracy: 78.58%
2024-02-18 12:53:32 - INFO - Epoch [6/10], Loss: 0.0638, Accuracy: 97.84%
2024-02-18 12:53:36 - INFO - Epoch [6/10], Validation Loss: 0.9057, Validation Accuracy: 78.52%
2024-02-18 12:56:07 - INFO - Epoch [7/10], Loss: 0.0485, Accuracy: 98.34%
2024-02-18 12:56:11 - INFO - Epoch [7/10], Validation Loss: 0.9381, Validation Accuracy: 78.42%
2024-02-18 12:58:41 - INFO - Epoch [8/10], Loss: 0.0390, Accuracy: 98.70%
2024-02-18 12:58:46 - INFO - Epoch [8/10], Validation Loss: 0.9798, Validation Accuracy: 78.78%
2024-02-18 13:01:51 - INFO - Epoch [9/10], Loss: 0.0327, Accuracy: 98.87%
2024-02-18 13:01:56 - INFO - Epoch [9/10], Validation Loss: 0.9940, Validation Accuracy: 78.97%
2024-02-18 13:04:27 - INFO - Epoch [10/10], Loss: 0.0287, Accuracy: 99.02%
2024-02-18 13:04:31 - INFO - Epoch [10/10], Validation Loss: 1.1447, Validation Accuracy: 78.65%
2024-02-18 13:04:36 - INFO - Test Loss: 1.1553, Test Accuracy: 78.42%
2024-02-18 13:07:34 - INFO - ==========New Line==========
2024-02-18 13:07:34 - INFO - For 0 sample, the processed tweet content is: hey dear happy friday to you already had your rice is bowl for lunch
2024-02-18 13:07:34 - INFO - For 1 sample, the processed tweet content is: ughhh layin downnnn waiting for zeina to cook breakfast
2024-02-18 13:07:34 - INFO - For 2 sample, the processed tweet content is: i reckon he will play even if he is not but i know nothing it wont be the same without him
2024-02-18 13:07:34 - INFO - For 3 sample, the processed tweet content is: i know saw it on the news
2024-02-18 13:07:34 - INFO - For 4 sample, the processed tweet content is: very sad that has closed down one of the few web services that i have used for over years
2024-02-18 13:07:57 - INFO - Training and evaluating Logistic Regression...
2024-02-18 13:07:57 - INFO - Training and evaluating Multinomial Naive Bayes...
2024-02-18 13:07:57 - INFO - Accuracy for Multinomial Naive Bayes: 0.7707556919607904
2024-02-18 13:07:57 - INFO - Training and evaluating XGBoost...
2024-02-18 13:07:58 - INFO - Classification Report for Multinomial Naive Bayes:
              precision    recall  f1-score   support

           0       0.75      0.81      0.78     15981
           1       0.79      0.73      0.76     15950

    accuracy                           0.77     31931
   macro avg       0.77      0.77      0.77     31931
weighted avg       0.77      0.77      0.77     31931

2024-02-18 13:07:58 - INFO - --------------------------------------------------
2024-02-18 13:08:03 - INFO - Accuracy for XGBoost: 0.7617049262472205
2024-02-18 13:08:03 - INFO - Classification Report for XGBoost:
              precision    recall  f1-score   support

           0       0.79      0.71      0.75     15981
           1       0.74      0.81      0.77     15950

    accuracy                           0.76     31931
   macro avg       0.76      0.76      0.76     31931
weighted avg       0.76      0.76      0.76     31931

2024-02-18 13:08:03 - INFO - --------------------------------------------------
2024-02-18 13:08:05 - INFO - Accuracy for Logistic Regression: 0.7841595941248317
2024-02-18 13:08:05 - INFO - Classification Report for Logistic Regression:
              precision    recall  f1-score   support

           0       0.79      0.77      0.78     15981
           1       0.78      0.80      0.79     15950

    accuracy                           0.78     31931
   macro avg       0.78      0.78      0.78     31931
weighted avg       0.78      0.78      0.78     31931

2024-02-18 13:08:05 - INFO - --------------------------------------------------
2024-02-18 13:08:06 - INFO - Number of Tokenized features are 40
2024-02-18 13:08:07 - INFO - Tokenizer is gpt2-large
2024-02-18 13:08:19 - INFO - embed_size:1024
2024-02-18 13:08:19 - INFO - hidden_size:1024
2024-02-18 13:08:19 - INFO - output_size:1
2024-02-18 13:08:19 - INFO - batch_size:8
2024-02-18 13:08:19 - INFO - learning_rate:0.0001
2024-02-18 13:11:25 - INFO - Epoch [1/10], Loss: 0.5503, Accuracy: 69.97%
2024-02-18 13:11:29 - INFO - Epoch [1/10], Validation Loss: 0.4738, Validation Accuracy: 77.62%
2024-02-18 13:14:35 - INFO - Epoch [2/10], Loss: 0.4148, Accuracy: 81.07%
2024-02-18 13:14:39 - INFO - Epoch [2/10], Validation Loss: 0.4550, Validation Accuracy: 78.74%
2024-02-18 13:17:44 - INFO - Epoch [3/10], Loss: 0.3203, Accuracy: 86.32%
2024-02-18 13:17:49 - INFO - Epoch [3/10], Validation Loss: 0.4826, Validation Accuracy: 79.21%
2024-02-18 13:20:51 - INFO - Epoch [4/10], Loss: 0.2012, Accuracy: 92.09%
2024-02-18 13:20:55 - INFO - Epoch [4/10], Validation Loss: 0.6032, Validation Accuracy: 77.88%
2024-02-18 13:29:23 - INFO - Epoch [5/10], Loss: 0.1079, Accuracy: 96.15%
2024-02-18 13:29:27 - INFO - Epoch [5/10], Validation Loss: 0.7089, Validation Accuracy: 77.83%
2024-02-18 13:32:29 - INFO - Epoch [6/10], Loss: 0.0689, Accuracy: 97.66%
2024-02-18 13:32:34 - INFO - Epoch [6/10], Validation Loss: 0.8442, Validation Accuracy: 77.66%
2024-02-18 13:35:36 - INFO - Epoch [7/10], Loss: 0.0521, Accuracy: 98.23%
2024-02-18 13:35:41 - INFO - Epoch [7/10], Validation Loss: 0.9227, Validation Accuracy: 77.99%
2024-02-18 13:38:43 - INFO - Epoch [8/10], Loss: 0.0411, Accuracy: 98.65%
2024-02-18 13:38:48 - INFO - Epoch [8/10], Validation Loss: 0.9540, Validation Accuracy: 77.58%
2024-02-18 13:41:50 - INFO - Epoch [9/10], Loss: 0.0360, Accuracy: 98.80%
2024-02-18 13:41:55 - INFO - Epoch [9/10], Validation Loss: 0.9371, Validation Accuracy: 77.07%
2024-02-18 13:44:57 - INFO - Epoch [10/10], Loss: 0.0305, Accuracy: 98.98%
2024-02-18 13:45:02 - INFO - Epoch [10/10], Validation Loss: 1.1483, Validation Accuracy: 77.77%
2024-02-18 13:45:06 - INFO - Test Loss: 1.1476, Test Accuracy: 77.63%
2024-02-20 11:06:35 - INFO - ==========New Line==========
2024-02-20 11:06:35 - INFO - For 0 sample, the processed tweet content is: hey dear happy friday to you already had your rice is bowl for lunch
2024-02-20 11:06:35 - INFO - For 1 sample, the processed tweet content is: ughhh layin downnnn waiting for zeina to cook breakfast
2024-02-20 11:06:35 - INFO - For 2 sample, the processed tweet content is: i reckon he will play even if he is not but i know nothing it wont be the same without him
2024-02-20 11:06:35 - INFO - For 3 sample, the processed tweet content is: i know saw it on the news
2024-02-20 11:06:35 - INFO - For 4 sample, the processed tweet content is: very sad that has closed down one of the few web services that i have used for over years
2024-02-20 11:06:35 - INFO - Number of Tokenized features are 40
2024-02-20 11:06:37 - INFO - Tokenizer is gpt2-large
2024-02-20 11:06:49 - INFO - embed_size:1024
2024-02-20 11:06:49 - INFO - hidden_size:1024
2024-02-20 11:06:49 - INFO - output_size:1
2024-02-20 11:06:49 - INFO - batch_size:8
2024-02-20 11:06:49 - INFO - learning_rate:0.0001
2024-02-20 11:09:56 - INFO - Epoch [1/10], Loss: 0.6886, Accuracy: 53.67%
2024-02-20 11:10:01 - INFO - Epoch [1/10], Validation Loss: 0.6844, Validation Accuracy: 56.54%
2024-02-20 11:12:16 - INFO - ==========New Line==========
2024-02-20 11:12:16 - INFO - For 0 sample, the processed tweet content is: hey dear happy friday to you already had your rice is bowl for lunch
2024-02-20 11:12:16 - INFO - For 1 sample, the processed tweet content is: ughhh layin downnnn waiting for zeina to cook breakfast
2024-02-20 11:12:16 - INFO - For 2 sample, the processed tweet content is: i reckon he will play even if he is not but i know nothing it wont be the same without him
2024-02-20 11:12:16 - INFO - For 3 sample, the processed tweet content is: i know saw it on the news
2024-02-20 11:12:16 - INFO - For 4 sample, the processed tweet content is: very sad that has closed down one of the few web services that i have used for over years
2024-02-20 11:12:16 - INFO - Number of Tokenized features are 40
2024-02-20 11:12:16 - INFO - Tokenizer is gpt2-large
2024-02-20 11:12:29 - INFO - embed_size:1024
2024-02-20 11:12:29 - INFO - hidden_size:1024
2024-02-20 11:12:29 - INFO - output_size:1
2024-02-20 11:12:29 - INFO - batch_size:8
2024-02-20 11:12:29 - INFO - learning_rate:0.0001
2024-02-20 11:15:36 - INFO - Epoch [1/10], Loss: 0.6886, Accuracy: 53.67%
2024-02-20 11:15:41 - INFO - Epoch [1/10], Validation Loss: 0.6844, Validation Accuracy: 56.54%
2024-02-20 11:18:48 - INFO - Epoch [2/10], Loss: 0.6570, Accuracy: 60.08%
2024-02-20 11:18:53 - INFO - Epoch [2/10], Validation Loss: 0.5639, Validation Accuracy: 72.32%
2024-02-20 11:22:00 - INFO - Epoch [3/10], Loss: 0.4952, Accuracy: 76.46%
2024-02-20 11:22:04 - INFO - Epoch [3/10], Validation Loss: 0.4758, Validation Accuracy: 77.80%
2024-02-20 11:25:11 - INFO - Epoch [4/10], Loss: 0.4095, Accuracy: 81.52%
2024-02-20 11:25:16 - INFO - Epoch [4/10], Validation Loss: 0.4582, Validation Accuracy: 78.98%
2024-02-20 11:28:23 - INFO - Epoch [5/10], Loss: 0.3227, Accuracy: 86.17%
2024-02-20 11:28:27 - INFO - Epoch [5/10], Validation Loss: 0.4757, Validation Accuracy: 79.19%
2024-02-20 11:31:31 - INFO - Epoch [6/10], Loss: 0.2192, Accuracy: 91.34%
2024-02-20 11:31:36 - INFO - Epoch [6/10], Validation Loss: 0.5424, Validation Accuracy: 77.90%
2024-02-20 11:34:40 - INFO - Epoch [7/10], Loss: 0.1320, Accuracy: 95.17%
2024-02-20 11:34:44 - INFO - Epoch [7/10], Validation Loss: 0.7021, Validation Accuracy: 78.10%
2024-02-20 11:37:48 - INFO - Epoch [8/10], Loss: 0.0845, Accuracy: 97.07%
2024-02-20 11:37:53 - INFO - Epoch [8/10], Validation Loss: 0.7462, Validation Accuracy: 77.76%
2024-02-20 11:40:57 - INFO - Epoch [9/10], Loss: 0.0613, Accuracy: 97.92%
2024-02-20 11:41:01 - INFO - Epoch [9/10], Validation Loss: 0.8136, Validation Accuracy: 77.22%
2024-02-20 11:44:05 - INFO - Epoch [10/10], Loss: 0.0503, Accuracy: 98.28%
2024-02-20 11:44:10 - INFO - Epoch [10/10], Validation Loss: 0.9491, Validation Accuracy: 77.46%
2024-02-20 11:44:14 - INFO - Test Loss: 0.9446, Test Accuracy: 77.33%
2024-02-20 12:26:47 - INFO - ==========New Line==========
2024-02-20 12:26:47 - INFO - For 0 sample, the processed tweet content is: hey dear happy friday to you already had your rice is bowl for lunch
2024-02-20 12:26:47 - INFO - For 1 sample, the processed tweet content is: ughhh layin downnnn waiting for zeina to cook breakfast
2024-02-20 12:26:47 - INFO - For 2 sample, the processed tweet content is: i reckon he will play even if he is not but i know nothing it wont be the same without him
2024-02-20 12:26:47 - INFO - For 3 sample, the processed tweet content is: i know saw it on the news
2024-02-20 12:26:47 - INFO - For 4 sample, the processed tweet content is: very sad that has closed down one of the few web services that i have used for over years
2024-02-20 12:26:47 - INFO - Number of Tokenized features are 40
2024-02-20 12:26:47 - INFO - Tokenizer is bert-base-uncased
2024-02-20 12:27:02 - INFO - embed_size:256
2024-02-20 12:27:02 - INFO - hidden_size:512
2024-02-20 12:27:02 - INFO - output_size:1
2024-02-20 12:27:02 - INFO - batch_size:8
2024-02-20 12:27:02 - INFO - learning_rate:0.0001
2024-02-20 12:29:00 - INFO - Epoch [1/10], Loss: 0.5676, Accuracy: 69.43%
2024-02-20 12:29:03 - INFO - Epoch [1/10], Validation Loss: 0.4898, Validation Accuracy: 76.23%
2024-02-20 12:31:03 - INFO - Epoch [2/10], Loss: 0.4611, Accuracy: 78.44%
2024-02-20 12:31:05 - INFO - Epoch [2/10], Validation Loss: 0.4570, Validation Accuracy: 78.40%
2024-02-20 12:33:05 - INFO - Epoch [3/10], Loss: 0.4148, Accuracy: 81.23%
2024-02-20 12:33:07 - INFO - Epoch [3/10], Validation Loss: 0.4412, Validation Accuracy: 79.64%
2024-02-20 12:35:04 - INFO - Epoch [4/10], Loss: 0.3715, Accuracy: 83.78%
2024-02-20 12:35:07 - INFO - Epoch [4/10], Validation Loss: 0.4435, Validation Accuracy: 80.01%
2024-02-20 12:37:03 - INFO - Epoch [5/10], Loss: 0.3234, Accuracy: 86.32%
2024-02-20 12:37:06 - INFO - Epoch [5/10], Validation Loss: 0.4629, Validation Accuracy: 78.97%
2024-02-20 12:39:02 - INFO - Epoch [6/10], Loss: 0.2664, Accuracy: 89.19%
2024-02-20 12:39:05 - INFO - Epoch [6/10], Validation Loss: 0.4803, Validation Accuracy: 78.96%
2024-02-20 12:41:01 - INFO - Epoch [7/10], Loss: 0.2090, Accuracy: 91.92%
2024-02-20 12:41:04 - INFO - Epoch [7/10], Validation Loss: 0.5549, Validation Accuracy: 78.85%
2024-02-20 12:43:00 - INFO - Epoch [8/10], Loss: 0.1587, Accuracy: 94.14%
2024-02-20 12:43:02 - INFO - Epoch [8/10], Validation Loss: 0.6182, Validation Accuracy: 78.30%
2024-02-20 12:44:59 - INFO - Epoch [9/10], Loss: 0.1212, Accuracy: 95.76%
2024-02-20 12:45:01 - INFO - Epoch [9/10], Validation Loss: 0.7126, Validation Accuracy: 77.87%
2024-02-20 12:46:57 - INFO - Epoch [10/10], Loss: 0.0959, Accuracy: 96.79%
2024-02-20 12:47:00 - INFO - Epoch [10/10], Validation Loss: 0.7775, Validation Accuracy: 78.19%
2024-02-20 12:47:02 - INFO - Test Loss: 0.7881, Test Accuracy: 78.14%
2024-02-20 12:56:11 - INFO - ==========New Line==========
2024-02-20 12:56:11 - INFO - For 0 sample, the processed tweet content is: hey dear happy friday to you already had your rice is bowl for lunch
2024-02-20 12:56:11 - INFO - For 1 sample, the processed tweet content is: ughhh layin downnnn waiting for zeina to cook breakfast
2024-02-20 12:56:11 - INFO - For 2 sample, the processed tweet content is: i reckon he will play even if he is not but i know nothing it wont be the same without him
2024-02-20 12:56:11 - INFO - For 3 sample, the processed tweet content is: i know saw it on the news
2024-02-20 12:56:11 - INFO - For 4 sample, the processed tweet content is: very sad that has closed down one of the few web services that i have used for over years
2024-02-20 12:56:12 - INFO - Number of Tokenized features are 40
2024-02-20 12:56:12 - INFO - Tokenizer is bert-base-uncased
2024-02-20 12:56:28 - INFO - embed_size:128
2024-02-20 12:56:28 - INFO - hidden_size:256
2024-02-20 12:56:28 - INFO - output_size:1
2024-02-20 12:56:28 - INFO - batch_size:8
2024-02-20 12:56:28 - INFO - learning_rate:1e-05
2024-02-20 12:58:19 - INFO - Epoch [1/20], Loss: 0.6863, Accuracy: 53.26%
2024-02-20 12:58:22 - INFO - Epoch [1/20], Validation Loss: 0.6577, Validation Accuracy: 62.07%
2024-02-21 00:35:48 - INFO - ==========New Line==========
2024-02-21 00:35:49 - INFO - For 0 sample, the processed tweet content is: hey dear happy friday to you already had your rice is bowl for lunch
2024-02-21 00:35:49 - INFO - For 1 sample, the processed tweet content is: ughhh layin downnnn waiting for zeina to cook breakfast
2024-02-21 00:35:49 - INFO - For 2 sample, the processed tweet content is: i reckon he will play even if he is not but i know nothing it wont be the same without him
2024-02-21 00:35:49 - INFO - For 3 sample, the processed tweet content is: i know saw it on the news
2024-02-21 00:35:49 - INFO - For 4 sample, the processed tweet content is: very sad that has closed down one of the few web services that i have used for over years
2024-02-21 00:35:49 - INFO - Number of Tokenized features are 40
2024-02-21 00:35:49 - INFO - Tokenizer is bert-base-uncased
2024-02-21 00:36:08 - INFO - embed_size:1024
2024-02-21 00:36:08 - INFO - hidden_size:1024
2024-02-21 00:36:08 - INFO - output_size:1
2024-02-21 00:36:08 - INFO - batch_size:8
2024-02-21 00:36:08 - INFO - learning_rate:1e-05
2024-02-21 00:39:15 - INFO - Epoch [1/20], Loss: 0.5405, Accuracy: 71.47%
2024-02-21 00:39:20 - INFO - Epoch [1/20], Validation Loss: 0.4870, Validation Accuracy: 76.61%
2024-02-21 00:42:25 - INFO - Epoch [2/20], Loss: 0.4597, Accuracy: 78.53%
2024-02-21 00:42:31 - INFO - Epoch [2/20], Validation Loss: 0.4679, Validation Accuracy: 77.83%
2024-02-21 00:45:35 - INFO - Epoch [3/20], Loss: 0.4243, Accuracy: 80.61%
2024-02-21 00:45:40 - INFO - Epoch [3/20], Validation Loss: 0.4548, Validation Accuracy: 78.44%
2024-02-21 00:48:38 - INFO - Epoch [4/20], Loss: 0.3946, Accuracy: 82.40%
2024-02-21 00:48:43 - INFO - Epoch [4/20], Validation Loss: 0.4550, Validation Accuracy: 79.22%
2024-02-21 00:51:41 - INFO - Epoch [5/20], Loss: 0.3652, Accuracy: 84.09%
2024-02-21 00:51:47 - INFO - Epoch [5/20], Validation Loss: 0.4509, Validation Accuracy: 79.08%
2024-02-21 00:54:53 - INFO - Epoch [6/20], Loss: 0.3352, Accuracy: 85.76%
2024-02-21 00:54:58 - INFO - Epoch [6/20], Validation Loss: 0.4665, Validation Accuracy: 79.21%
2024-02-21 00:57:58 - INFO - Epoch [7/20], Loss: 0.3041, Accuracy: 87.32%
2024-02-21 00:58:03 - INFO - Epoch [7/20], Validation Loss: 0.4758, Validation Accuracy: 78.50%
2024-02-21 01:01:08 - INFO - Epoch [8/20], Loss: 0.2728, Accuracy: 88.89%
2024-02-21 01:01:13 - INFO - Epoch [8/20], Validation Loss: 0.5246, Validation Accuracy: 78.46%
2024-02-21 01:04:07 - INFO - Epoch [9/20], Loss: 0.2427, Accuracy: 90.34%
2024-02-21 09:23:56 - INFO - ==========New Line==========
2024-02-21 09:23:57 - INFO - For 0 sample, the processed tweet content is: hey dear happy friday to you already had your rice is bowl for lunch
2024-02-21 09:23:57 - INFO - For 1 sample, the processed tweet content is: ughhh layin downnnn waiting for zeina to cook breakfast
2024-02-21 09:23:57 - INFO - For 2 sample, the processed tweet content is: i reckon he will play even if he is not but i know nothing it wont be the same without him
2024-02-21 09:23:57 - INFO - For 3 sample, the processed tweet content is: i know saw it on the news
2024-02-21 09:23:57 - INFO - For 4 sample, the processed tweet content is: very sad that has closed down one of the few web services that i have used for over years
2024-02-21 09:23:57 - INFO - Number of Tokenized features are 40
2024-02-21 09:23:58 - INFO - Tokenizer is bert-base-uncased
2024-02-21 09:24:18 - INFO - embed_size:1024
2024-02-21 09:24:18 - INFO - hidden_size:1024
2024-02-21 09:24:18 - INFO - output_size:1
2024-02-21 09:24:18 - INFO - batch_size:16
2024-02-21 09:24:18 - INFO - learning_rate:0.0001
2024-02-21 09:26:06 - INFO - Epoch [1/20], Loss: 0.5264, Accuracy: 73.73%
2024-02-21 09:26:10 - INFO - Epoch [1/20], Validation Loss: 0.4689, Validation Accuracy: 78.28%
2024-02-21 09:27:57 - INFO - Epoch [2/20], Loss: 0.4259, Accuracy: 80.63%
2024-02-21 09:28:01 - INFO - Epoch [2/20], Validation Loss: 0.4450, Validation Accuracy: 79.67%
2024-02-21 09:29:50 - INFO - Epoch [3/20], Loss: 0.3574, Accuracy: 84.42%
2024-02-21 09:29:53 - INFO - Epoch [3/20], Validation Loss: 0.4350, Validation Accuracy: 79.75%
2024-02-21 09:31:42 - INFO - Epoch [4/20], Loss: 0.2754, Accuracy: 88.71%
2024-02-21 09:31:45 - INFO - Epoch [4/20], Validation Loss: 0.4964, Validation Accuracy: 79.50%
2024-02-21 09:33:32 - INFO - Epoch [5/20], Loss: 0.1887, Accuracy: 92.82%
2024-02-21 09:33:36 - INFO - Epoch [5/20], Validation Loss: 0.5823, Validation Accuracy: 78.92%
2024-02-21 09:35:23 - INFO - Epoch [6/20], Loss: 0.1223, Accuracy: 95.60%
2024-02-21 09:35:27 - INFO - Epoch [6/20], Validation Loss: 0.6887, Validation Accuracy: 78.40%
2024-02-21 09:37:14 - INFO - Epoch [7/20], Loss: 0.0869, Accuracy: 96.93%
2024-02-21 09:37:18 - INFO - Epoch [7/20], Validation Loss: 0.7753, Validation Accuracy: 78.55%
2024-02-21 09:39:05 - INFO - Epoch [8/20], Loss: 0.0719, Accuracy: 97.48%
2024-02-21 09:39:09 - INFO - Epoch [8/20], Validation Loss: 0.8353, Validation Accuracy: 78.70%
2024-02-21 09:40:55 - INFO - Epoch [9/20], Loss: 0.0674, Accuracy: 97.74%
2024-02-21 09:40:59 - INFO - Epoch [9/20], Validation Loss: 0.8427, Validation Accuracy: 78.32%
2024-02-21 09:42:47 - INFO - Epoch [10/20], Loss: 0.0603, Accuracy: 98.01%
2024-02-21 09:42:51 - INFO - Epoch [10/20], Validation Loss: 0.8143, Validation Accuracy: 78.27%
2024-02-21 09:44:38 - INFO - Epoch [11/20], Loss: 0.0521, Accuracy: 98.32%
2024-02-21 09:44:42 - INFO - Epoch [11/20], Validation Loss: 0.9152, Validation Accuracy: 78.60%
2024-02-21 09:46:28 - INFO - Epoch [12/20], Loss: 0.0394, Accuracy: 98.77%
2024-02-21 09:46:32 - INFO - Epoch [12/20], Validation Loss: 0.8208, Validation Accuracy: 78.36%
2024-02-21 09:48:20 - INFO - Epoch [13/20], Loss: 0.0360, Accuracy: 98.82%
2024-02-21 09:48:24 - INFO - Epoch [13/20], Validation Loss: 1.0897, Validation Accuracy: 78.88%
2024-02-21 09:50:11 - INFO - Epoch [14/20], Loss: 0.0318, Accuracy: 98.98%
2024-02-21 09:50:15 - INFO - Epoch [14/20], Validation Loss: 1.0262, Validation Accuracy: 78.44%
2024-02-21 09:52:02 - INFO - Epoch [15/20], Loss: 0.0287, Accuracy: 99.05%
2024-02-21 09:52:06 - INFO - Epoch [15/20], Validation Loss: 0.9995, Validation Accuracy: 78.51%
2024-02-21 09:53:53 - INFO - Epoch [16/20], Loss: 0.0252, Accuracy: 99.17%
2024-02-21 09:53:57 - INFO - Epoch [16/20], Validation Loss: 1.1870, Validation Accuracy: 78.29%
2024-02-21 09:55:45 - INFO - Epoch [17/20], Loss: 0.0248, Accuracy: 99.16%
2024-02-21 09:55:48 - INFO - Epoch [17/20], Validation Loss: 1.1172, Validation Accuracy: 78.42%
2024-02-21 09:57:36 - INFO - Epoch [18/20], Loss: 0.0208, Accuracy: 99.28%
2024-02-21 09:57:40 - INFO - Epoch [18/20], Validation Loss: 1.2154, Validation Accuracy: 78.50%
2024-02-21 09:59:26 - INFO - Epoch [19/20], Loss: 0.0192, Accuracy: 99.31%
2024-02-21 09:59:30 - INFO - Epoch [19/20], Validation Loss: 1.2660, Validation Accuracy: 78.03%
2024-02-21 10:01:16 - INFO - Epoch [20/20], Loss: 0.0219, Accuracy: 99.25%
2024-02-21 10:01:20 - INFO - Epoch [20/20], Validation Loss: 1.1530, Validation Accuracy: 78.04%
2024-02-21 10:01:24 - INFO - Test Loss: 1.1324, Test Accuracy: 78.41%
